{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HindiSeq2Seq_Attention_beam_search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMexVepYitpK",
        "colab_type": "code",
        "outputId": "aeefb0b6-f3c3-48ae-8df5-073ebd07547f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-iM0iSiizNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train_df= pd.read_csv('/content/drive/My Drive/project/hindiDataCleaned.csv', engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWd1EtyjEmk",
        "colab_type": "code",
        "outputId": "a2b924b4-a983-4a14-8e30-dc292440c4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "train_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>headline</th>\n",
              "      <th>summary</th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>रिम करेगा दो हजार कर्मचारियों की छंटनी</td>\n",
              "      <td>sostok ब्लैकबेरी हैंडसेट बनाने वाली कनाडा की क...</td>\n",
              "      <td>ब्लैकबेरी हैंडसेट बनाने वाली कनाडा कंपनी रिसर्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>अमेरिका : राष्ट्रपति पद की उम्मीदवार हिलेरी क्...</td>\n",
              "      <td>sostok श्रद्धांजलि सभा के दौरान अचानक खराब हुई...</td>\n",
              "      <td>अमेरिका राष्ट्रपति पद डेमोक्रेटिक पार्टी उम्मी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>देश के सर्वश्रेष्ठ स्पिनरों में से एक है हरभजन...</td>\n",
              "      <td>sostok पूर्व भारतीय कप्तान अनिल कुंबले का मानन...</td>\n",
              "      <td>पूर्व भारतीय क्रिकेट कप्तान अनिल कुंबले मानना ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>इंडिगो के स्टाफ ने दिल्ली एयरपोर्ट पर पैसेंजर ...</td>\n",
              "      <td>sostok इंडिगो के ग्राउंड स्टाफ ने यात्री से की...</td>\n",
              "      <td>इंडिगो एयरलाइन प्रेसीडेंट डायरेक्टर आदित्य घोष...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>नव्या नवेली के साथ दोस्ती पर जावेद जाफरी के बे...</td>\n",
              "      <td>sostok मीजान जाफरी ने किया खुलासा नव्या नंदा क...</td>\n",
              "      <td>संजय लीला भंसाली फिल्म मलाल बॉलीवुड कदम रखने म...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12</td>\n",
              "      <td>इस्लामिक धर्मगुरु ने रियल एस्टेट में किया 100 ...</td>\n",
              "      <td>sostok ज़ाकिर नाइक के बैंक खातों की एनआईए जांच...</td>\n",
              "      <td>विवादित इस्लामिक प्रचारक ज़ाकिर नाइक गैर सरकार...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13</td>\n",
              "      <td>राष्ट्रपति 9 दिवसीय दौरे पर सेशेल्स व द. अफ्री...</td>\n",
              "      <td>sostok राष्ट्रपति प्रतिभा पाटील रविवार सुबह से...</td>\n",
              "      <td>राष्ट्रपति प्रतिभा पाटील रविवार सुबह सेशेल्स द...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>17</td>\n",
              "      <td>पीएम मोदी मिले बीजेपी के ओबीसी सांसदों से, सरक...</td>\n",
              "      <td>sostok कहा जब संसद नहीं चल रही हो तो अपने क्षे...</td>\n",
              "      <td>उन्होंने क्षेत्रों समस्याओं लेकर केंद्रीय मंत्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>18</td>\n",
              "      <td>Bharat New Poster: सलमान खान दिखे बुजुर्ग के ग...</td>\n",
              "      <td>sostok सलमान खान दिखे बुजुर्ग के गेटअप में उनक...</td>\n",
              "      <td>खान तस्वीर ट्वीट लिखा जितने सफेद बाल मेरे सिर ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23</td>\n",
              "      <td>सोमालियाई लुटेरों ने 17 भारतीयों को किया रिहा</td>\n",
              "      <td>sostok फरवरी में इटली के इस जहाज का अपहरण किया...</td>\n",
              "      <td>रोम सोमालियाई समुद्री लुटेरों इटली तेल भरे जहा...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            article\n",
              "0           3  ...  ब्लैकबेरी हैंडसेट बनाने वाली कनाडा कंपनी रिसर्...\n",
              "1           7  ...  अमेरिका राष्ट्रपति पद डेमोक्रेटिक पार्टी उम्मी...\n",
              "2           8  ...  पूर्व भारतीय क्रिकेट कप्तान अनिल कुंबले मानना ...\n",
              "3           9  ...  इंडिगो एयरलाइन प्रेसीडेंट डायरेक्टर आदित्य घोष...\n",
              "4          10  ...  संजय लीला भंसाली फिल्म मलाल बॉलीवुड कदम रखने म...\n",
              "5          12  ...  विवादित इस्लामिक प्रचारक ज़ाकिर नाइक गैर सरकार...\n",
              "6          13  ...  राष्ट्रपति प्रतिभा पाटील रविवार सुबह सेशेल्स द...\n",
              "7          17  ...  उन्होंने क्षेत्रों समस्याओं लेकर केंद्रीय मंत्...\n",
              "8          18  ...  खान तस्वीर ट्वीट लिखा जितने सफेद बाल मेरे सिर ...\n",
              "9          23  ...  रोम सोमालियाई समुद्री लुटेरों इटली तेल भरे जहा...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjdNheCV2S-I",
        "colab_type": "code",
        "outputId": "c85abc46-11e2-473d-af97-4a19f8a52907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df['summary'][13]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sostok गुजरात के मुख्यमंत्री नरेंद्र मोदी ने कहा कि उत्तराखंड पर जो प्राकृतिक विपदा आई है वह राष्ट्रीय आपदा जैसी है उन्होंने कहा हम इस संकट से निबटने में राज्य सरकार को जो भी मदद कर सकते हैं करेंगे eostok'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-buPROnjM9X",
        "colab_type": "code",
        "outputId": "0fe03d6d-b989-4cbd-d55c-e0fdde76f6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fp= open('/content/drive/My Drive/project/hi.tsv', \"r\", encoding=\"utf-8\")\n",
        "content= fp.read()\n",
        "\n",
        "lines= content.split(']')\n",
        "# s, value= lines[0].split('[')\n",
        "# print( lines[0].split('['))\n",
        "\n",
        "embeddings_index = {}\n",
        "for line in lines:\n",
        "  if len(line.split()) > 1:\n",
        "    s, value= line.split('[')\n",
        "    num, word= s.split()\n",
        "    embedding= value.split()\n",
        "    embedding= [float(x) for x in embedding] \n",
        "    embeddings_index[word] = embedding\n",
        "print(len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCqk_6CalD8Q",
        "colab_type": "code",
        "outputId": "94ec1a93-65a1-4b8a-913c-f5f1061dee87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embeddings_index['के']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLzLohUrlH6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr,x_test,y_tr,y_test = train_test_split(train_df['article'],train_df['summary'],test_size=0.1,random_state=0,shuffle=True) \n",
        "\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_tr,y_tr,test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbt4wJaybUPD",
        "colab_type": "code",
        "outputId": "b7e6f52d-3e3c-4f15-8152-c376ee530c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "x_tr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30627    गैलप शुक्रवार आए ताजा सर्वे मुताबिक अमेरिकी रा...\n",
              "45967    अमरनाथ यात्रियों हमले बहाने बीजेपी सत्ता सहयोग...\n",
              "34197    भारत स्टार बल्लेबाज सचिन तेंदुलकर काफी समय जार...\n",
              "17005    क्यूबा लिंग परिवर्तन कराने वालों संख्या गई जान...\n",
              "28704    दिल्ली मेट्रो पूर्व प्रमुख मेट्रो मैन नाम मशहू...\n",
              "                               ...                        \n",
              "1086     नागरिकता संशोधन कानून खिलाफ देश जगह प्रदर्शन ब...\n",
              "7173     भारत स्टार टेनिस खिलाड़ी सोमदेव देवबर्मन पेशेव...\n",
              "25009    कारोबारी सप्ताह तीसरे दिन कारोबार अंत हल्की गि...\n",
              "17823    माल्या अदालत बाहर पत्रकारों बताया मैं अदालत बच...\n",
              "54434    बिहार मुख्यमंत्री नीतीश कुमार चलाए दहेज बाल वि...\n",
              "Name: article, Length: 45452, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvVze8uIcqKp",
        "colab_type": "code",
        "outputId": "c350c40a-bab0-4073-efd1-1dbf2af6378c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5051,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAL1vcrydZVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr2= list(x_tr)\n",
        "x_val2= list(x_val)\n",
        "x_test2= list(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZGJtutalKQs",
        "colab_type": "code",
        "outputId": "2382582e-cc62-4e6f-a593-6834c5fc0f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print('Training data: ', len(x_tr))\n",
        "print('Validation data: ', len(x_val))\n",
        "print('Testing data:', len(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data:  45452\n",
            "Validation data:  5051\n",
            "Testing data: 5612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9Q1bXMpdm3O",
        "colab_type": "code",
        "outputId": "08ed9d26-8fa9-47cd-e051-216a554e8306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print('Training data: ', len(x_tr2))\n",
        "print('Validation data: ', len(x_val2))\n",
        "print('Testing data:', len(x_test2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data:  45452\n",
            "Validation data:  5051\n",
            "Testing data: 5612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra8ub_GvlMQ_",
        "colab_type": "code",
        "outputId": "e9ce4ea1-61fb-4434-87bf-65dd5a92220e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from attention import AttentionLayer\n",
        "import warnings\n",
        "\n",
        "from keras import backend as K \n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRR4BfNilx6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text= 400\n",
        "max_len_summary= 35"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3yeBnx-lQ4k",
        "colab_type": "code",
        "outputId": "ffab5708-21e3-4ece-b1c8-1822ca5ab7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#before_sample=x_tr[80186]\n",
        "# Tokenizer library in keras that maps words to integers, integers to words\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "x_tr_int    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_int   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "x_test_int = x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# padding zero upto maximum length\n",
        "x_tr_int    =   pad_sequences(x_tr_int,  maxlen=max_len_text, padding='post') \n",
        "x_val_int   =   pad_sequences(x_val_int, maxlen=max_len_text, padding='post')\n",
        "x_test_int   =   pad_sequences(x_test_int, maxlen=max_len_text, padding='post')\n",
        "\n",
        "print(len(x_tr_int))\n",
        "# after_sample=x_tr[88280]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mIMPvrAlc7v",
        "colab_type": "code",
        "outputId": "cb23f4e3-eed2-4c19-8a27-ba0144d3539e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "after_sample=x_tr_int[45]\n",
        "print(after_sample)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  174    56  1878   287  1878  4759  1710   362  4977   933   105  1710\n",
            "  5010  1093    31   328   341  4050 11810    34  2818   274   328  1710\n",
            "   174  1738    38  5010  5011  5290  2456  2735  1095    35   193  1470\n",
            "    34 12566   216  3623   218  1710   430   127   341  1710   174 28399\n",
            "  1591  8763  1127  1547  2561  3044   408   789   829 28400 79572  7824\n",
            " 15968 95214   309 17591  1710   174  1854  2731   239 28399   341  1710\n",
            "   174   832   282  1591  1710  5010   418    78  1710  1281    26  1710\n",
            "  5010   341  1710   174 11810    78  2818   328   930   189   403    34\n",
            "  1710  1281  5010 11231    55 14587 28399   341  1710   174   333 95215\n",
            " 21232   680 95216 11052 20553  1931  1521 28399  1434  2144 54381    26\n",
            "   448 21233   362   119  1710   174  1699   230   320  1841  1878   517\n",
            "   218  1739  2457  3423  2340 25098  1710  1041  1854    57  1973 95217\n",
            " 54382  1710  1878 54382  1739  4565]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-wKCuPTlnF5",
        "colab_type": "code",
        "outputId": "6efc8725-3808-447b-dd7e-d3d30752d36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#print(\"Aricle Before: \\n\"+str(before_sample[0:250]))\n",
        "print()\n",
        "print(\"Article After: \\n\"+str(after_sample[0:250]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Article After: \n",
            "[  174    56  1878   287  1878  4759  1710   362  4977   933   105  1710\n",
            "  5010  1093    31   328   341  4050 11810    34  2818   274   328  1710\n",
            "   174  1738    38  5010  5011  5290  2456  2735  1095    35   193  1470\n",
            "    34 12566   216  3623   218  1710   430   127   341  1710   174 28399\n",
            "  1591  8763  1127  1547  2561  3044   408   789   829 28400 79572  7824\n",
            " 15968 95214   309 17591  1710   174  1854  2731   239 28399   341  1710\n",
            "   174   832   282  1591  1710  5010   418    78  1710  1281    26  1710\n",
            "  5010   341  1710   174 11810    78  2818   328   930   189   403    34\n",
            "  1710  1281  5010 11231    55 14587 28399   341  1710   174   333 95215\n",
            " 21232   680 95216 11052 20553  1931  1521 28399  1434  2144 54381    26\n",
            "   448 21233   362   119  1710   174  1699   230   320  1841  1878   517\n",
            "   218  1739  2457  3423  2340 25098  1710  1041  1854    57  1973 95217\n",
            " 54382  1710  1878 54382  1739  4565]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixxEDQNWlqa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\n",
        "\n",
        "# same for summaries\n",
        "y_tr_int    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_int   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "#y_test_int= y_tokenizer.texts_to_sequences(y_test)\n",
        "\n",
        "y_tr_int    =   pad_sequences(y_tr_int, maxlen=max_len_summary, padding='post')\n",
        "y_val_int   =   pad_sequences(y_val_int, maxlen=max_len_summary, padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDmdx6BUl88B",
        "colab_type": "code",
        "outputId": "237cdfb4-c48c-47d9-9d44-b16fa8bbfedb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr_int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45452, 45452)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZCpDrA3mZCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3iLOE6Wl-1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding matrix to be used in model\n",
        "embedding_dim= 300\n",
        "\n",
        "x_embedding_matrix= np.zeros((x_voc_size, embedding_dim))\n",
        "\n",
        "for word, i in x_tokenizer.word_index.items():\n",
        "  if i> x_voc_size:\n",
        "    continue\n",
        "  embedding_vector= embeddings_index.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    x_embedding_matrix[i]= embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCain3RdmhGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding matrix for decoder to be used in model\n",
        "y_embedding_matrix= np.zeros((y_voc_size, embedding_dim))\n",
        "for word, i in y_tokenizer.word_index.items():\n",
        "  if word == 'sostok':\n",
        "    embedding_vector = np.array(np.random.uniform(-1.0, 1.0, embedding_dim)) \n",
        "  if word == 'eostok':\n",
        "    embedding_vector = np.array(np.random.uniform(-1.0, 1.0, embedding_dim)) \n",
        "    \n",
        "  if i> y_voc_size:\n",
        "    continue\n",
        "  embedding_vector= embeddings_index.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    y_embedding_matrix[i]= embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnxKzX-bl--c",
        "colab_type": "code",
        "outputId": "18f106d3-4a4a-4266-901b-fd4846428df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y_embedding_matrix[10]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M82e9wCJl_JP",
        "colab_type": "code",
        "outputId": "bdced6dd-628c-436c-e3f1-71bd103c4205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(x_embedding_matrix.shape)\n",
        "print(y_embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(127576, 300)\n",
            "(42329, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKjJdmN-mF4g",
        "colab_type": "code",
        "outputId": "96ea7c72-1e74-4dfc-d235-f1771723b06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "latent_dim = 300\n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,embeddings_initializer= Constant(x_embedding_matrix), trainable=False)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_output1, forward_h, forward_c, backward_h, backward_c = encoder_lstm1(enc_emb)\n",
        "\n",
        "#LSTM 2 \n",
        "# encoder output 1 is fed as input to the next lstm\n",
        "encoder_lstm2 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_output2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#LSTM 3 \n",
        "# encoder output 2 fed as input to next lstm \n",
        "encoder_lstm3=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\n",
        "encoder_output3, forward_h3, forward_c3, backward_h3, backward_c3 = encoder_lstm3(encoder_output2)\n",
        "\n",
        "#LSTM 4\n",
        "encoder_lstm4=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\n",
        "encoder_outputs, forward_h4, forward_c4, backward_h4, backward_c4 = encoder_lstm2(encoder_output3)\n",
        "state_h = Concatenate()([forward_h4, backward_h4])\n",
        "state_c = Concatenate()([forward_c4, backward_c4])\n",
        "encoder_states = [state_h, state_c]\n",
        "print(state_h.shape)\n",
        "print(state_c.shape)\n",
        "#encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 600)\n",
            "(None, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1B3WqdSmGE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from attention import AttentionLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm_GDyo-mGUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer=  Embedding(y_voc_size, latent_dim,embeddings_initializer= Constant(y_embedding_matrix), trainable=False)\n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM1\n",
        "# Using encoder_states as decoder's initial state\n",
        "decoder_lstm1 = LSTM(2*latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm1(dec_emb,initial_state=encoder_states) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOcEFh1RmGQm",
        "colab_type": "code",
        "outputId": "b43a1c11-dcf5-431d-ab48-8c8225643691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# early stopping \n",
        "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 400, 300)     38272800    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 400, 600), ( 1442400     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 400, 600), ( 2162400     bidirectional[0][0]              \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 400, 600), ( 2162400     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    12698700    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 600)          0           bidirectional_1[1][1]            \n",
            "                                                                 bidirectional_1[1][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           bidirectional_1[1][2]            \n",
            "                                                                 bidirectional_1[1][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 600),  2162400     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 600),  720600      bidirectional_1[1][0]            \n",
            "                                                                 lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1200)   0           lstm_4[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 42329)  50837129    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 110,458,829\n",
            "Trainable params: 59,487,329\n",
            "Non-trainable params: 50,971,500\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4YFLmLd2I0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odRaq483mGNo",
        "colab_type": "code",
        "outputId": "4bb7a860-5804-423a-c420-cc592424b039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "history=model.fit([x_tr_int,y_tr_int[:,:-1]], y_tr_int.reshape(y_tr_int.shape[0],\n",
        "                                                               y_tr_int.shape[1], 1)[:,1:] ,\n",
        "                  epochs=10,batch_size=64, \n",
        "                  validation_data=([x_val_int,y_val_int[:,:-1]], \n",
        "                                   y_val_int.reshape(y_val_int.shape[0],y_val_int.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "711/711 [==============================] - 1238s 2s/step - loss: 4.7895 - val_loss: 4.2454\n",
            "Epoch 2/10\n",
            "711/711 [==============================] - 1244s 2s/step - loss: 4.1302 - val_loss: 4.0152\n",
            "Epoch 3/10\n",
            "711/711 [==============================] - 1246s 2s/step - loss: 3.8782 - val_loss: 3.8929\n",
            "Epoch 4/10\n",
            "711/711 [==============================] - 1247s 2s/step - loss: 3.6963 - val_loss: 3.8374\n",
            "Epoch 5/10\n",
            "711/711 [==============================] - 1248s 2s/step - loss: 3.5408 - val_loss: 3.7943\n",
            "Epoch 6/10\n",
            "711/711 [==============================] - 1250s 2s/step - loss: 3.3994 - val_loss: 3.7651\n",
            "Epoch 7/10\n",
            "711/711 [==============================] - 1249s 2s/step - loss: 3.2640 - val_loss: 3.7665\n",
            "Epoch 8/10\n",
            "164/711 [=====>........................] - ETA: 15:21 - loss: 3.0246"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSTTiLy_1-1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "#model = load_model('/content/drive/My Drive/my_model3.h5',custom_objects={'AttentionLayer': AttentionLayer})\n",
        "model.save('/content/drive/My Drive/project/my_model_attn_beam.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#path = '/content/drive/My Drive/my_model4.h5'\n",
        "#model.save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMtXdTMfmGB8",
        "colab_type": "code",
        "outputId": "50a97201-b2e7-45be-9c8d-fbfc64916cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='val')  \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3wUdf7H8dcnnVBCgNBSSAgivQakdxFRESt4ouIhnF1Pz3q/Oz2u2Mt5gopYsByo2LCLUqRjUDooSWihJSQQCCWkfH5/7CIhl7KBTSbZfJ6Pxz4yO/Od2c+u8t7Zme98R1QVY4wxvsvP6QKMMcZULAt6Y4zxcRb0xhjj4yzojTHGx1nQG2OMjwtwuoDiNGrUSGNjY50uwxhjqo1Vq1btV9WI4pZ5HPQi4g8kArtU9eIiy8YDTwG73LNeVNXp7mU3AP/nnv8PVZ1R1mvFxsaSmJjoaWnGGFPjicj2kpaVZ4/+LmATUK+E5e+p6u1FXrgB8AiQACiwSkTmqOqBcryuMcaYs+DRMXoRiQIuAqaXc/sXAHNVNdMd7nOBEeXchjHGmLPg6cnY54H7gYJS2lwhImtFZLaIRLvnRQI7C7VJdc8zxhhTSco8dCMiFwNpqrpKRAaV0OwzYKaq5ojIH4AZwJDyFCIik4BJADExMeVZ1RhjyM3NJTU1lePHjztdSoUKCQkhKiqKwMBAj9fx5Bh9X2CUiIwEQoB6IvKOqo472UBVMwq1nw486Z7eBQwqtCwKWFDci6jqNGAaQEJCgg3AY4wpl9TUVOrWrUtsbCwi4nQ5FUJVycjIIDU1lbi4OI/XK/PQjao+pKpRqhoLjAXmFQ55ABFpVujpKFwnbQG+AYaLSLiIhAPD3fOMMcarjh8/TsOGDX025AFEhIYNG5b7V8sZ96MXkclAoqrOAe4UkVFAHpAJjAdQ1UwR+Tvwo3u1yaqaeaavaYwxpfHlkD/pTN5juYJeVRfgPvSiqn8tNP8h4KES1nkdeL3clZVTfoHyyg/J9IlvRJfo+hX9csYYU234zBAIR07k8fay7dzz/mqO5+Y7XY4xpoY5ePAgU6dOLfd6I0eO5ODBgxVQ0Sk+E/T1QgJ56srOpKQf4YmvNztdjjGmhikp6PPy8kpd78svv6R+/Yo9CuEzQQ/Q75xG3NC7BW8s2cbSpP1Ol2OMqUEefPBBkpOT6dKlCz169KB///6MGjWKdu3aATB69Gi6d+9O+/btmTZt2m/rxcbGsn//frZt20bbtm2ZOHEi7du3Z/jw4Rw7dswrtVXJQc3OxoMXtuWHLfu5b/Zavrq7P/VCPO9raozxDX/7bAMbdx/y6jbbNa/HI5e0L3H5448/zvr161m9ejULFizgoosuYv369b91g3z99ddp0KABx44do0ePHlxxxRU0bNjwtG1s2bKFmTNn8uqrr3L11Vfz4YcfMm7cuOJerlx8ao8eoFaQP89c3Zk9WceY/NlGp8sxxtRQPXv2PK2v+wsvvEDnzp3p1asXO3fuZMuWLf+zTlxcHF26dAGge/fubNu2zSu1+NwePUC3mHBuGRTPlPnJDG/XhOHtmzpdkjGmEpW2511Zateu/dv0ggUL+O6771i2bBmhoaEMGjSo2L7wwcHBv037+/t77dCNz+3Rn3TX0Na0bVaPhz9eR0Z2jtPlGGN8XN26dTl8+HCxy7KysggPDyc0NJTNmzezfPnySq3NZ4M+KMCP58Z05tCxPB7+eB2qNqqCMabiNGzYkL59+9KhQwfuu+++05aNGDGCvLw82rZty4MPPkivXr0qtTapigGYkJCg3rrxyMsLk3n8q808e3VnLu8W5ZVtGmOqnk2bNtG2bVuny6gUxb1XEVmlqgnFtffZPfqTJvZvSUKLcB6Zs4HdB71zvMsYY6oTnw96fz/hmas7k1+g3D97LQUFVe8XjDHGVCSfD3qAFg1r8/DItixO2s87K0q8raIxxvikGhH0ANeeF8OA1hH868tNbN1/xOlyjDGm0tSYoBcRnryiE0H+ftzz/mry8ku7K6IxxviOGhP0AE3DQvj76A78vOMgr/yQ4nQ5xhhTKWpU0AOM6tycizo24/nvfvX6WBjGGOOpOnXqVNpr1bigFxH+ProD9UODuOf91eTk2dj1xhjfVuOCHqBB7SCeuKIjm/ce5rm5/zuwkDHGlNeDDz7IlClTfnv+6KOP8o9//IOhQ4fSrVs3OnbsyKeffupIbT45qJknhrRpwtge0Uz7IZlhbRuTENvA6ZKMMd7y1YOwd513t9m0I1z4eImLx4wZw913381tt90GwPvvv88333zDnXfeSb169di/fz+9evVi1KhRlX5v2xq5R3/S/13cjub1a3HvB2s4klP6XWCMMaY0Xbt2JS0tjd27d7NmzRrCw8Np2rQpDz/8MJ06dWLYsGHs2rWLffv2VXptNXaPHqBOcABPX9WZa15dzmNfbeIfozs6XZIxxhtK2fOuSFdddRWzZ89m7969jBkzhnfffZf09HRWrVpFYGAgsbGxxQ5PXNE83qMXEX8R+VlEPi9m2T0islFE1orI9yLSotCyfBFZ7X7M8Vbh3tKrZUMm9I3jneU7WPhrutPlGGOqsTFjxjBr1ixmz57NVVddRVZWFo0bNyYwMJD58+ezfbszV+aX59DNXcCmEpb9DCSoaidgNvBkoWXHVLWL+zHqDOusUH+64FxaNa7D/bPXkHU01+lyjDHVVPv27Tl8+DCRkZE0a9aMa6+9lsTERDp27Mhbb71FmzZtHKnLo0M3IhIFXAT8E7in6HJVnV/o6XLg7G9yWIlCAv157uouXDZ1CY/MWc/zY7s6XZIxpppat+7USeBGjRqxbNmyYttlZ2dXVkke79E/D9wPeDJuwATgq0LPQ0QkUUSWi8jo8hZYWTpGhXH7kFZ8sno3X67b43Q5xhjjNWUGvYhcDKSp6ioP2o4DEoCnCs1u4R4M/3fA8yISX8K6k9xfCInp6c4cK79tcCs6RYXx54/XkXa48k+YGGNMRfBkj74vMEpEtgGzgCEi8k7RRiIyDPgzMEpVf7tJq6rucv9NARYAxR4XUdVpqpqgqgkRERHlfR9eEejvx7NXd+bIiXwe+tBuP2hMdVMT/s2eyXssM+hV9SFVjVLVWGAsME9VTzsGLyJdgVdwhXxaofnhIhLsnm6E60tjY7mrrEStGtflgRFt+H5zGh8kpjpdjjHGQyEhIWRkZPh02KsqGRkZhISElGu9M+5HLyKTgURVnYPrUE0d4AP3FV873D1s2gKviEgBri+Vx1W1Sgc9wI19Ypm7cS9/+2wDveMbEt0g1OmSjDFliIqKIjU1FacO/VaWkJAQoqLKd/9rn785+JnamXmUC/+9iPbN6zFzYi/8/Cr3kmVjjCmPmnNz8I1zIDut7HYeiG4Qyl8vbseKrZm8vmSrV7ZpjDFO8J2gP5oJn9wK0wbDnrVe2eRVCVEMa9uYJ7/5haS0w17ZpjHGVDbfCfrQBjD+c0Dh9QtgwydnvUkR4V+Xd6R2kD/3vL+GXLv9oDGmGvKdoAdo3gUmzocmHeCDG2D+v6Dg7MK5cd0Q/nVZR9amZjFlfpKXCjXGmMrjW0EPULeJa8++y7Ww8An44HrIObtLjS/s2IzRXZrz4rwk1qYe9FKhxhhTOXwv6AECguHSKXDBY7D5C9ehnANnN2rc30Z1oFGdYO55fw3Hc+32g8aY6sM3gx5ABHrfCtd+AAd3wquDYfvSM95cWGggT17ZiaS0bJ7+5hcvFmqMMRXLd4P+pFbDYOI8qNUAZlwCq948400NaB3BuF4xvLZkK8tTMrxXozHGVCDfD3qARq3gpu+g5SD47C748j7IP7Nx5x8e2ZaYBqH86YM1HD5uY9cbY6q+mhH0ALXqw+/eh963w8pp8M7lrr735RQaFMCzV3dm98Fj/OPzku7DYowxVUfNCXoAP3+44J8w+iXYsRxeHQJpm8u9me4tGvCHgfG8l7iT7zdV/o1+jTGmPGpW0J/U5Xcw/kvIPQrTh8EvX5d7E3cPO4c2TevywIfryDxyogKKNMYY76iZQQ8Q3cN1cVXDeJg5FhY/B+UY4C04wJ9nr+5C1rET/OWT9T49NKoxpnqruUEPEBYJN34FHS6H7x6FjyZC7jGPV2/XvB53D2vNF+v2MGfN7oqr0xhjzkLNDnqAoFC44jUY+ldYNxveuBAOeR7afxjQkm4x9fnLJ+vZm2W3HzTGVD0W9OC6uKr/vTD2v7B/i2sEzFTPxsMP8Pfjmau7kJuv3P/hWjuEY4ypcizoC2szEibMdQ2h8MZIWPOeR6vFNarNwyPb8MOv6by7YkcFF2mMMeVjQV9Uk3YwaQFE94SPJ8G3f4GCsse2GderBf3PacQ/v9jEtv1HKrxMY4zxlAV9cUIbwHUfQ4+bYOkLrl45x7NKXUVEePLKTgT4C3/6YA35BXYIxxhTNVjQl8Q/EC56Bi56FpLnufrbZySXukqzsFpMvrQ9idsPcOesnzl6Iq+SijXGmJJZ0JelxwS4/lM4st81AmbyvFKbj+4SyUMXtuHLdXu44qVl7Mw8WkmFGmNM8SzoPRHbDybNh3pR8M6VsPzlEi+uEhH+MDCe18f3IPXAUS6dsoRlyTbSpTHGOR4HvYj4i8jPIvJ5McuCReQ9EUkSkRUiElto2UPu+b+IyAXeKdsB4bEw4Rs490L4+gGYcwfk5ZTYfPC5jfn0tr6EhwYy7rUVzFi6zbpeGmMcUZ49+ruAkoZrnAAcUNVWwHPAEwAi0g4YC7QHRgBTRcT/zMt1WHBduPptGHA//Pw2zBgF2WklNm8ZUYdPbuvL4HMjeGTOBh78cB05eXZ3KmNM5fIo6EUkCrgImF5Ck0uBGe7p2cBQERH3/FmqmqOqW4EkoOfZlewwPz8Y8me48g3Ys8Z1cdWetSU2rxsSyLTrErhjSCveS9zJNdOWk3bIrqA1xlQeT/fonwfuBwpKWB4J7ARQ1TwgC2hYeL5bqnve/xCRSSKSKCKJ6enpHpbloA6Xw++/BtR1T9oNH5fY1M9PuHf4uUy9thub9hzmkhcXs3qn3WTcGFM5ygx6EbkYSFPVVRVZiKpOU9UEVU2IiIioyJfynuZdXBdXNe0IH4yH+f+CgpK+C2Fkx2Z8dGsfAv39uPqVZcxelVpZlRpjajBP9uj7AqNEZBswCxgiIu8UabMLiAYQkQAgDMgoPN8tyj3Pd9RpDDd8Bl3GwcIn4IPrISe7xOZtm9Vjzu396B4Tzp8+WMPkzzaSl1/yl4MxxpytMoNeVR9S1ShVjcV1YnWeqo4r0mwOcIN7+kp3G3XPH+vulRMHnAOs9Fr1VUVAMFz6IlzwGGz+wnUoZ817cHBnsc0b1A7irQk9Gd8nlteXbOWGN1ZywG5eYoypIAFnuqKITAYSVXUO8BrwtogkAZm4vhBQ1Q0i8j6wEcgDblNV3+x2IgK9b4WIc+HjP7jGyQEIi4YWfVyPmD7Q6BwQIdDfj0dHtadd83r838frGTVlMa9en0CbpvWcfR/GGJ8jVbFvd0JCgiYmejZMcJVUkA9pG2H7Uti+BLYvgyPubpihjU4Ff4s+0KQDP6Ue4ua3V5Gdk8ezV3dmRIdmztZvjKl2RGSVqiYUu8yCvhKousbJ2bH0VPgfdA9nHFwPos/jcNOe/HN9fT7a25ibh7Tl7mGt8fMTZ+s2xlQbFvRVUVaqa09/+xLYsQzSNwOQK0Ek5rVif8NuDB1xGaEte0NQbYeLNcZUdRb01cGRDNixDN2+hIwNCwg/tAl/UdQvAGnW2X2opy9En+caRtkYYwqxoK+GVmzcyowPPqCrbuSqiFTqZ66BfHfPnMbtoUXvUyd469kxfWNqOgv6ampn5lEmvpXIr/sO8/D5cUxoeQA5eZx/50o44e6vHx7n2ts/Gf7hca5eQMaYGsOCvho7kpPHfbPX8OW6vVzapTlPXNGJkEB/yM+DvWtdob9jmevvsUzXSnWbQUxviO0L546Ees2dfRPGmApnQV/NqSpT5ifxzNxfad+8Hq9cl0Bk/VqnNyoogP2/urtzuvf6D+8GBGJ6QbvR0G6Uhb4xPsqC3kd8t3Efd7+3mpBAP14a150esaWclFV1Bf/GT2HDJ5C2wTU/uhe0Hw1tR0FYsePLGWOqIQt6H5KUdpiJb60i9cBRHh3VnmvPa+HZivu3uAJ/4yewb71rXvR57j39Sy30janmLOh9TNaxXO6c+TMLf03n2vNieOSS9gQFlOMeMvuTYOPHsOFT2LfONS+qp2tPv92lEBZVMYUbYyqMBb0Pyi9QnvrmF15emEyP2HCmXtudiLrB5d/Q/iTXXv7GT2DvydDvcWpPv3506esbY6oEC3of9unqXTzw4VrCQ4OYdl0CHaPCznxjGcmuG6gUDv3IhFN7+vVjvFO0McbrLOh93PpdWUx6K5GMIyd48spOXNrFC8fbM5Jdgb/hE1c3ToDI7q49/fajLfSNqWIs6GuA/dk53PrOT6zclsmkAS15YEQb/L01KFpGsqv3zsZPXPfJBWjezb2nPxrCPTwhbIypMBb0NcSJvAImf76Bd5bvYEDrCP4ztithoYHefZHMlFNdNvesds1r3vXUnn54rHdfzxjjEQv6Gmbmyh389dP1RNavxdNXdSahtP72ZyNz66k9/d0/u+ZZ6BvjCAv6GihxWyZ3zVrNroPH+N15MTwwog1htby8d1/YgW2n9vR3/+Sa16yLK/BbXwgN48G/Al/fmBrOgr6GOpKTx3Nzf+X1JVtpWCeYRy9pz8iOTZGKHvCsuNAXf9ex/IatoEG8K/gbxrumw6LAz79iazLGx1nQ13DrUrN46OO1rN91iKFtGjN5dIf/HSunohzYDtsWQ2ay66RuRrJrOvfoqTb+wdAgzv0l0NL1t2G862+dJjYSpzEesKA35OUX8ObSbTzz7a+IwL3Dz2V8n1jv9cwpD1U4vMcd/EnuL4EU1/SBrafG3QcIquMO//givwZa2Q1YjCnEgt78ZmfmUf766Xrm/5JOx8gwHru8Ix0iz+IiK28ryIesnafv/WckuaYPbgctONU2pP7pe/+Ffw0E13XuPRjjgLMKehEJAX4AgoEAYLaqPlKkzXPAYPfTUKCxqtZ3L8sH3JdZskNVR5VVsAV9xVJVvli3h0fnbCTzSA4T+sXxx/NbExoU4HRppcs74Qr7k8Ff+NfAodTT29Zp4t77b3nql0C9SAis5X6EQlAoBNQC/yr+vs3ZK8iHnMNw4ojrhj0nsiHH/ffEEdehxN+ysEgmnpaRpS2jlGVawvwiywJrQffxpb6Vkpxt0AtQW1WzRSQQWAzcparLS2h/B9BVVX/vfp6tqnXKU7AFfeXIOprL419vZubKHUTWr8U/RndgcJvGTpd1Zk4cdR32+e1LoNCvgSPppa/rH3Qq/E/7W3i6djHzimkXVLv4Zf5Bdq6hPPJOFAnkI3DicKHp7NOD+7fQLqF93jGn35FnajeG+7ac0aqlBX2ZuzLq+iZw37OOQPejtG+Ha4BHSlluqoiw0EAeu7wjl3eL5KGP1nHjmz9ycadm/PWSdjSuG+J0eeUTFApN2rseRR3PcgV/dprrH3zuMdceXK57+sSR/513cvrYwf+ddyahIX6nwt8/2PUrwi/Q1eXUL8D9t7jnJbTzCzjDbRR6rgWg+VCQ59rjLTg5nedadnK66HIt1K6gSLvT1iu07dPWKfxaue5QPuIOZXd4Fz5PU9bnGlTX9QUbXMd1TieotmswvpPTwXWKaVPn9OnAWq5t/bbdol/KUgHLKGZZxewMeHSMXkT8gVVAK2CKqj5QQrsWwHIgSlXz3fPygNVAHvC4qn5SwrqTgEkAMTEx3bdv317+d2POWE5ePq8sTOHFeUmEBPrx0Mi2jEmIxs+Jk7VVXUEB5B0v8uVQ+G9x8wp9qeTnugLut795hZ7nlTC/lHaFz1s4xS+g0MPf1Z228HM/9/Pf5heaF1TbHbx1C02XEMjB7vA+GdyBteyXkpvXTsaKSH3gY+AOVV1fzPIHcIX8HYXmRarqLhFpCcwDhqpqcmmvY4dunJOcns3DH61jxdZMesSG89jlHWnV2E5sVmkFBR5+cRR5Ln6nwlgKBW/Rv6eFdtF13POM47za60ZE/gocVdWni1n2M3Cbqi4tYd03gc9VdXZpr2FB7yxV5YPEVP755SaOnsjjlkGtuHVQvOum5MaYKqm0oC/zq1hEItx78ohILeB8YHMx7doA4cCyQvPCRSTYPd0I6AtsPJM3YSqPiHB1j2i+v3cgIzs244XvtzDyhUUsT8lwujRjzBnw5DdXM2C+iKwFfgTmqurnIjJZRAp3lRwLzNLTfyK0BRJFZA0wH9cxegv6aqJRnWD+PbYrM37fk9z8AsZOW84Ds9dy8KiHJ8qMMVWCXTBlPHLsRD7Pf/8r0xdtJTw0kL9c3I5RnZtX/Lg5xhiPnNWhG2MAagX589CFbZlze18i69firlmrueGNH9mZebTslY0xjrKgN+XSvnkYH93al0cuaceqbZmc/9xCXlmYTF5+FejiZ4wplgW9KTd/P+HGvnHMvWcg/VpF8NhXmxn14hLW7DzodGnGmGJY0Jsz1rx+LV69vjsvj+vG/uwcLpu6hEfnbCA7J8/p0owxhVjQm7MiIozo0Izv7h3Itee1YMaybZz/7ELmbtzndGnGGDcLeuMV9UIC+fvoDsy+uQ/1QgKZ+FYit7yzin2HjjtdmjE1ngW98aruLcL57I5+3HfBuXy/OY1hzyzkrWXb7GStMQ6yoDdeFxTgx22DW/Ht3QPoFB3GXz/dwIX/XsT8X9KoitdtGOPrLOhNhYltVJt3JpzHy+O6cSK/gBvf+JHrXlvJpj2HnC7NmBrFgt5UqJMna+f+cSB/ubgd63ZlMfKFRTwwe60dvzemktgQCKZSHTx6gv/MS+KtZdsI8PPjDwNbMmlAy6p/G0NjqjgbAsFUGfVDg/jLxe347p6BDG4TwfPfbWHw0wt4P3En+QVVb6fDGF9gQW8c0aJhbaZe253ZN/emWVgt7p+9lov/s5jFW/Y7XZoxPseC3jgqIbYBH9/ahxeu6cqhY7mMe20Fv3/zR7bsO+x0acb4DAt64zgRYVTn5nx/70AevLANP27NZMS/F/Hnj9exPzvH6fKMqfYs6E2VERLoz80D41l4/2DGnRfDrB93MuipBUyZn8Tx3HynyzOm2rKgN1VOg9pB/O3SDnz7xwH0atmQp775haHPLOSTn3dRYCdsjSk3C3pTZcVH1GH6DQnMnNiL8NqB3P3eakZPXcIKu3etMeViQW+qvN7xDZlzWz+evboz6YdzGDNtOZPeSiQlPdvp0oypFizoTbXg5ydc3i2KefcO4k/DW7MkaT/Dn/uBR+ds4MARu1m5MaWxoDfVSq0gf24fcg7z7xvEVQnRvLVsGwOfms+rP6SQk2cnbI0pTplBLyIhIrJSRNaIyAYR+VsxbcaLSLqIrHY/biq07AYR2eJ+3ODtN2BqpsZ1Q3js8o58ffcAurUI559fbmLYswv5fO1uGyHTmCLKHOtGRASorarZIhIILAbuUtXlhdqMBxJU9fYi6zYAEoEEQIFVQHdVPVDaa9pYN6a8Fm1J559fbGLz3sN0i6nPny9qR/cW4U6XZUylOauxbtTl5FmvQPfD012mC4C5qprpDve5wAgP1zXGY/3PieCLO/vzxBUd2XngGFe8tJTb/vsTOzOPOl2aMY7z6Bi9iPiLyGogDVdwryim2RUislZEZotItHteJLCzUJtU97ziXmOSiCSKSGJ6eno53oIxLv5+wpgeMSz40yDuHHoO32/ax9BnFvKvLzeRdSzX6fKMcYxHQa+q+araBYgCeopIhyJNPgNiVbUTrr32GeUtRFWnqWqCqiZERESUd3VjflM7OIB7zm/Ngj8N5tIuzXl1UQoDn5rP64u32glbUyOVq9eNqh4E5lPk8IuqZqjqyUFJpgPd3dO7gOhCTaPc84ypcE3DQnjqqs58fkc/2jevx+TPNzL4qQXMWrnD7mFrahRPet1EiEh993Qt4Hxgc5E2zQo9HQVsck9/AwwXkXARCQeGu+cZU2naNw/j3Zt68e5N59G4XggPfrSOYc8u5NPVNqSCqRk8ua1PM2CGiPjj+mJ4X1U/F5HJQKKqzgHuFJFRQB6QCYwHUNVMEfk78KN7W5NVNdPbb8IYT/Rt1Yg+8Q35flMaT3/7C3fNWs1LC5K55/zWnN+uCa4OZsb4HruVoKmRCgqUz9ft4bm5v7J1/xE6R9fnT8Nb069VIwt8Uy3ZrQSNKcLPzzUG/tw/DuDJKzqx/3AO1722krHTlpO4zX50Gt9ie/TGADl5+cxcsYMX5yezPzuHwedGcO/wc+kQGeZ0acZ4pLQ9egt6Ywo5eiKPGUu38/LCZLKO5TKyY1PuOb81rRrXdbo0Y0plQW9MOR06nsv0RVt5bVEKx3LzGd01kj8Oa010g1CnSzOmWBb0xpyhjOwcXl6YzFvLtlOgypge0dwx5Bya1AtxujRjTmNBb8xZ2pt1nBfnb2HWyp34+wnX927BLYNa0aB2kNOlGQNY0BvjNTsyjvL897/yyc+7qBXoz4T+Lbmpfxz1QgKdLs3UcBb0xnhZUtphnp37K1+u20tYrUBuHhjPDX1aEBrkyTWIxnifBb0xFWT9riye+fYX5v+STqM6wdw+OJ5rzoshOMDf6dJMDWNBb0wFS9yWyVPf/MKKrZlE1q/FXUPP4fJukQT42zWJpnLYlbHGVLCE2AbMmtSLtyf0pFGdIO7/cC3Dn/uBOWt228BpxnEW9MZ4iYjQ/5wIPrmtL69c151Afz/unPkzI19YxNyN++xetsYxFvTGeJmIcEH7pnx5V3/+PbYLx3PzmfhWIpdNXcqSpP1Ol2dqIDtGb0wFy80v4MNVqbzw/RZ2Zx2nZ2wDbhkcz6DWETZSpvEaOxlrTBVwPDefWSt38MoPKezJOk7bZvW4ZVA8Izs0tZO25qxZ0BtThZzIK+DT1bt4eWEyyelHaNEwlEkDWnJFtyhCAq1bpjkzFvTGVEEFBcq3G/fx0oIk1qRmEVE3mAn94rj2vBjq2pW2ppws6I2pwlSVZckZTF2QzOKk/dQNCeD63i24sc/NvXYAAA6gSURBVG8cjeoEO12eqSYs6I2pJtamHuSlBcl8vWEvQf5+jOkRzcT+LW14ZFMmC3pjqpnk9GymLUzho59TKVAY1bk5Nw+M59ymdgMUUzwLemOqqT1Zx5i+aCszV+7g6Il8hrVtzC2DWtG9RbjTpZkq5qyCXkRCgB+AYCAAmK2qjxRpcw9wE5AHpAO/V9Xt7mX5wDp30x2qOqqsgi3ojTndgSMnmLFsG28u3cbBo7n0jGvArYPiGWh98Y3b2Qa9ALVVNVtEAoHFwF2qurxQm8HAClU9KiK3AINUdYx7Wbaq1ilPwRb0xhTv6Ik8Zq7cyfRFrr747U72xe/YDH8/C/ya7KwGNVOXbPfTQPdDi7SZr6pH3U+XA1FnUa8xpgShQQFM6BfHwvsG8+SVnTiel88dM39myDML+O+KHRzPzXe6RFMFeXSMXkT8gVVAK2CKqj5QStsXgb2q+g/38zxgNa7DOo+r6iclrDcJmAQQExPTffv27eV8K8bUPK6++HuZuiCZte6++Df1i+N31he/xvHayVgRqQ98DNyhquuLWT4OuB0YqKo57nmRqrpLRFoC84Chqppc2uvYoRtjykdVWZqcwdQFSSxJyqBeSADX945lfN9Y64tfQ5QW9OW675mqHhSR+cAI4LSgF5FhwJ8pFPLudXa5/6aIyAKgK1Bq0BtjykdE6NuqEX1bNWLNzoO8vDCZKQuSmL44hTEJ0dxkffFrtDKP0YtIhHtPHhGpBZwPbC7SpivwCjBKVdMKzQ8XkWD3dCOgL7DRe+UbY4rqHF2fl8Z1Z+4fBzKqc3P+u3IHg55ewD3vrebXfYedLs84wJNeN52AGYA/ri+G91V1sohMBhJVdY6IfAd0BPa4V9uhqqNEpA+uL4AC97rPq+prZRVlh26M8Z7dB4/x2uKt/HfFDo7l5jOsbRNuGRRvffF9jF0wZYzhwJETvLl0GzOWufri92rZgNsGt6Jfq0bWF98HWNAbY35zJCePmSt38OqiFPYdyqFzVBi3Dm7F+W2b4Gd98astC3pjzP/Iycvnw1WucfF3ZB6ldZM63DqoFRd3amY3QqmGLOiNMSXKyy/gi3V7mDI/iV/3ZRPTIJSbB8ZzRfdIggPsRijVhQW9MaZMBQXKd5v2MWW+60YoTeoFM7F/S353XgyhQeXqiW0cYEFvjPGYqrIkKYMX529heUom4aGB/L5vHNf3jiUs1K62raos6I0xZ2TV9kymzk/m+81p1AkOYFyvFkzoF0dEXbvatqqxoDfGnJWNuw8xdUESX6zbQ5C/H2N7RDNpYDyR9Ws5XZpxs6A3xnhFSno2Ly9M5qOfdgFwWddIbhkUT8uIco1EbiqABb0xxqt2HTzGqz+kMHPlDk7kFzCyYzNuHRRP++ZhTpdWY1nQG2MqxP7sHF5bvJW3l20nOyePIW0ac9vgeLq3aOB0aTWOBb0xpkJlHcvl7WXbeG3xVg7Y8AqOsKA3xlSKk7c6nPZDsg2vUMks6I0xlSonL5+PftrFSwtseIXKYkFvjHGEDa9QeSzojTGOsuEVKp4FvTGmSjh5b9sX5yWxLCWD8NBAxveJ4/reLQivHeR0edWaBb0xpspZtf0ALy1I4rtNaYQG+XNNzxgm9IujuV1te0Ys6I0xVdYvew/zysJkPl2zGwFGd43k5oEtadW4rtOlVSsW9MaYKi/1wFGmL9rKrB93cDy3gOHtXPe27Rpj97b1hAW9MabayMjOYcay7cxYuo2sY66Lr24Z1IoB59jFV6WxoDfGVDsn7207fdFW9h46Trtm9bhlUDwjOzbD3y6++h+lBX2ZVy6ISIiIrBSRNSKyQUT+VkybYBF5T0SSRGSFiMQWWvaQe/4vInLB2bwRY0zNUTs4gJv6t+SH+wfz5JWdOJ6Xzx0zf2bIMwt4d8V2jufmO11itVHmHr24fivVVtVsEQkEFgN3qeryQm1uBTqp6s0iMha4TFXHiEg7YCbQE2gOfAe0VtVS/wvZHr0xpqiCAuXbjft4aWEya3YepFGdYCb0i+PaXjHUC7E7X53VHr26ZLufBrofRb8dLgVmuKdnA0PdXxCXArNUNUdVtwJJuELfGGPKxc9PGNGhKZ/c2of/TjyPts3q8sTXm+n72Dye+HozaYePO11ileXRJWki4g+sAloBU1R1RZEmkcBOAFXNE5EsoKF7/vJC7VLd84p7jUnAJICYmJhyvAVjTE0iIvSJb0Sf+Eas35XFSwuTeWVhMq8t3spV3aOYNKAlLRrWdrrMKsWj0YVUNV9VuwBRQE8R6eDtQlR1mqomqGpCRESEtzdvjPFBHSLDmPK7bnx/7yCu6BbFB4mpDH56Abf/9yfW78pyurwqo1zDyKnqQWA+MKLIol1ANICIBABhQEbh+W5R7nnGGOM1cY1q89jlHVn8wGAmDYhnwS/pXPyfxVz/+kqWJWdQFXsXViZPet1EiEh993Qt4Hxgc5Fmc4Ab3NNXAvPU9cnOAca6e+XEAecAK71VvDHGFNa4XggPXtiGJQ8O4f4R57JxdxbXvLqcy6Yu5ZsNeykoqJmB70mvm064TrT64/pieF9VJ4vIZCBRVeeISAjwNtAVyATGqmqKe/0/A78H8oC7VfWrsoqyXjfGGG84npvP7FWpTPshhR2ZR4mPqM3NA+O5tEskQQG+NS6+XTBljKnR8vIL+HL9Xl5akMymPYdoFhbCTf1bMrZHNLWDfWOYZAt6Y4zBNUzywl/TeWlBMiu2ZhJWK5Ab+sQyvk8sDar5MMkW9MYYU8Sq7Qd4eWEyczfuIyTQj6u6RzOhXxyxjapn10wLemOMKcGWfYeZ9kMKn67eTW5BAee3bcLEAS1JaBFerQZRs6A3xpgypB0+zltLt/POiu0cPJpL5+j6TOwfx4j2TavFDc0t6I0xxkNHT+Tx4apUXlu8lW0ZR4kKr8WNfeMY0yOaOlX4xK0FvTHGlFO++4bm0xel8OO2A9QNCeB3PWMY3zeWZmFV73aHFvTGGHMWVu88yKuLUvhq3R78RLi4UzNu6t+SDpFhTpf2Gwt6Y4zxgp2ZR3ljyTbe+3EHR07k07tlQyYOiGNQ68b4OXwzFAt6Y4zxoqxjucxauYM3l25jT9ZxWjWuw4R+cVzWNZKQQH9HarKgN8aYCpCbX8AXa/fw6qIUNuw+RMPaQVzXuwXX9WpBwzrBlVqLBb0xxlQgVWVZSgbTF21l3uY0ggP8uLxbFDf1jyM+ok6l1FBa0FfdvkLGGFNNFL4ZSlLaYV5bvJUPf0pl5sodDG3TmIkDWnJeXAPHLsCyPXpjjKkA+7NzeHvZdt5evp3MIyfoGBnGTf3jGNmxGYEVcAGWHboxxhiHHM/N56OfdjF9cQop6UdoHhbC+L6xjO3p3ZuaW9AbY4zDCgqU+b+k8eqiFJanZFInOIAxPaK5sW8sUeGhZ719C3pjjKlC1u/K4tVFKXy+dg8AIzs2Y2L/ODpF1T/jbVrQG2NMFbT74DHeXLqNmSt2cDgnj55xDXjr9z3PqC++9boxxpgqqHn9Wjw8si13DGnFez/uJCktu0IuuLKgN8YYh9UNCeSm/i0rbPtVf5BlY4wxZ8WC3hhjfFyZh25EJBp4C2gCKDBNVf9dpM19wLWFttkWiFDVTBHZBhwG8oG8kk4WGGOMqRieHKPPA+5V1Z9EpC6wSkTmqurGkw1U9SngKQARuQT4o6pmFtrGYFXd783CjTHGeKbMQzequkdVf3JPHwY2AZGlrHINMNM75RljjDlb5TpGLyKxQFdgRQnLQ4ERwIeFZivwrYisEpFJpWx7kogkikhienp6ecoyxhhTCo+DXkTq4Arwu1X1UAnNLgGWFDls009VuwEXAreJyIDiVlTVaaqaoKoJERERnpZljDGmDB4FvYgE4gr5d1X1o1KajqXIYRtV3eX+mwZ8DPQ8s1KNMcaciTKHQBDXAMozgExVvbuUdmHAViBaVY+459UG/FT1sHt6LjBZVb8u4zXTge3leienNALsxK+LfRans8/jdPZ5nOILn0ULVS32cIgnvW76AtcB60RktXvew0AMgKq+7J53GfDtyZB3awJ87B5sPwD4b1kh797mGR+7EZFE68LpYp/F6ezzOJ19Hqf4+mdRZtCr6mKgzNuiqOqbwJtF5qUAnc+wNmOMMV5gV8YaY4yP88Wgn+Z0AVWIfRans8/jdPZ5nOLTn0WVHI/eGGOM9/jiHr0xxphCLOiNMcbH+UzQi8gIEflFRJJE5EGn63GSiESLyHwR2SgiG0TkLqdrcpqI+IvIzyLyudO1OE1E6ovIbBHZLCKbRKS30zU5SUT+6P53sl5EZopIiNM1eZtPBL2I+ANTcA2z0A64RkTaOVuVo06OONoO6IVr6Ima/HkA3IVrQD4D/wa+VtU2uLo/19jPRUQigTuBBFXtAPjjusLfp/hE0OMaViFJVVNU9QQwC7jU4ZoccwYjjvo0EYkCLgKmO12L09xXsA8AXgNQ1ROqetDZqhwXANQSkQAgFNjtcD1e5ytBHwnsLPQ8lRocbIWVNeJoDfE8cD9Q4HQhVUAckA684T6UNd09PEmN5B6L62lgB7AHyFLVb52tyvt8JehNMTwccdSnicjFQJqqrnK6lioiAOgGvKSqXYEjQI09pyUi4bh+/ccBzYHaIjLO2aq8z1eCfhcQXeh5lHtejVWOEUd9XV9glPuWlrOAISLyjrMlOSoVSFXVk7/wZuMK/ppqGLBVVdNVNRf4COjjcE1e5ytB/yNwjojEiUgQrpMpcxyuyTHuEUdfAzap6rNO1+MkVX1IVaNUNRbX/xfzVNXn9tg8pap7gZ0icq571lBgYymr+LodQC8RCXX/uxmKD56c9mT0yipPVfNE5HbgG1xnzV9X1Q0Ol+WkYkccVdUvHazJVB13AO+6d4pSgBsdrscxqrpCRGYDP+HqrfYzPjgcgg2BYIwxPs5XDt0YY4wpgQW9Mcb4OAt6Y4zxcRb0xhjj4yzojTHGx1nQG2OMj7OgN8YYH/f/NKNgXGbqE5QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl6cFa_rm3LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTN7ows6qjjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "#2 ideas : threshold value if less, remove and if end token found, remove and store in another list and then merge at the end\n",
        "\n",
        "def beam_search(encoder_model,decoder_model, src_input, k, sequence_max_len):\n",
        "\n",
        "    e_out, e_h, e_c = encoder_model.predict(src_input)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    start = True\n",
        "    \n",
        "    #print(k_beam)\n",
        "    # l : point on target sentence to predict\n",
        "    all_k_beams = [[[],1]]\n",
        "    load_hidden={}\n",
        "    end_sentence = []\n",
        "    for l in range(sequence_max_len):\n",
        "\n",
        "        if(start==True):\n",
        "\n",
        "          start=False\n",
        "          output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "          possible_k = output_tokens[0, -1, :].argsort()[-k:][::-1]\n",
        "          #print(\"Possible k in start: \"+str((possible_k)))\n",
        "          dummy_list = []\n",
        "          begin=True\n",
        "          for cand in all_k_beams:\n",
        "            \n",
        "            for curr_k in possible_k:\n",
        "              #print(\"Cand: \"+str(cand)+\" curr_k: \"+str(curr_k))\n",
        "              #print(cand[0]+[curr_k])\n",
        "              #print(cand[1]+np.log(output_tokens[0, -1, :][curr_k]))\n",
        "              curr = [cand[0]+[curr_k],cand[1]-np.log(output_tokens[0, -1, :][curr_k])]\n",
        "              \n",
        "              dummy_list.append(curr)\n",
        "              if(begin==True):\n",
        "                #target_seq = np.zeros((1,1))\n",
        "                #target_seq[0, 0] = curr_k\n",
        "                load_hidden[curr_k] = [h,c]\n",
        "            begin=False\n",
        "          all_k_beams = dummy_list[:]\n",
        "          #print(all_k_beams)\n",
        "          prev_target_seq = copy.deepcopy(possible_k)\n",
        "          #print(\"load_hidden: \"+str(load_hidden.keys()))\n",
        "        else:\n",
        "          #print(\"l is: \"+str(l))\n",
        "          #print(\"In else, prev target seq: \"+str(prev_target_seq))\n",
        "          for target_seq1 in prev_target_seq:\n",
        "            #print(\"Prev index: \"+str(target_seq1))\n",
        "            target_seq = np.zeros((1,1))\n",
        "            target_seq[0, 0] = target_seq1\n",
        "\n",
        "            output_tokens, h, c = decoder_model.predict([target_seq] + [e_out,load_hidden[target_seq1][0],load_hidden[target_seq1][1]])\n",
        "\n",
        "            possible_k = output_tokens[0, -1, :].argsort()[-k:][::-1]\n",
        "            #print(\"Possible k not in start: \"+str((possible_k)))\n",
        "\n",
        "            dummy_list = []\n",
        "            begin = True\n",
        "            for cand in all_k_beams:\n",
        "              for curr_k in possible_k:\n",
        "                if(cand[0][-1]==target_seq1 and len(cand[0])==l):\n",
        "                  #print(\"Here I am\")\n",
        "                  #print(\"Looking at cand: \"+str(cand[0]))\n",
        "                  ended=False\n",
        "                  curr = [cand[0]+[curr_k],cand[1]-np.log(output_tokens[0, -1, :][curr_k])]\n",
        "                  if(curr_k in reverse_target_word_index):\n",
        "                    sampled_token = reverse_target_word_index[curr_k]\n",
        "                    if(sampled_token=='end'):\n",
        "                      end_sentence.append(curr)\n",
        "                      ended=True\n",
        "                  if(ended==False):\n",
        "                    dummy_list.append(curr)\n",
        "                if(begin==True):\n",
        "                  #target_seq = np.zeros((1,1))\n",
        "                  #target_seq[0, 0] = curr_k\n",
        "                  load_hidden[curr_k] = [h,c]\n",
        "              begin=False\n",
        "            all_k_beams +=dummy_list\n",
        "            #print(all_k_beams)\n",
        "            prev_target_seq = copy.deepcopy(possible_k)\n",
        "        \n",
        "        # top k\n",
        "    #print(end_sentence)\n",
        "    all_k_beams += end_sentence\n",
        "    all_k_beams.sort(key=lambda r:r[1])\n",
        "    k_beam = all_k_beams[-k:]\n",
        "    #k_beam = k_beam[::-1]\n",
        "    return k_beam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2F4TzXmm3dG",
        "colab_type": "code",
        "outputId": "5037fb51-0890-449e-9698-89ca529799f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(reverse_source_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8_2qwlIm3iX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference Phase \n",
        "\n",
        "\"\"\"\n",
        "After training, the model is tested on new source sequences\n",
        "for which the target sequence is not known \n",
        "setting up inference architecture for it \n",
        "\"\"\"\n",
        "\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(2*latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(2*latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim*2))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm1(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg_J0zLypp7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence2(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    decoded_sentence = beam_search(encoder_model,decoder_model, input_seq, 3, 35)\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS_CI0y3m33D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "  newString=''\n",
        "  for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "          newString=newString+reverse_target_word_index[i]+' '\n",
        "  return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "  # print(input_seq)\n",
        "  newString=''\n",
        "  for i in input_seq:\n",
        "      if(i!=0):\n",
        "          newString=newString+reverse_source_word_index[i]+' '\n",
        "  return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu3ar561p2QL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentence(model_summary):\n",
        "  all_Sentence = []\n",
        "  for int_sent in model_summary:\n",
        "    sent = int_sent[0]\n",
        "    decoded_sentence= ''\n",
        "    for sampled_token_index in sent:\n",
        "      if sampled_token_index in reverse_target_word_index:\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "      else:\n",
        "        sampled_token=\"UNK\"\n",
        "            \n",
        "      if(sampled_token!='eostok'):\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else:\n",
        "        # print(\"broken\")\n",
        "        break\n",
        "    #print(str(decoded_sentence)+ \" , \"+str(int_sent[1]))\n",
        "    all_Sentence.append([decoded_sentence,int_sent[1]])\n",
        "  return all_Sentence "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWg6mVcOm3ZY",
        "colab_type": "code",
        "outputId": "b87162c9-605a-45d8-f806-74c367b6c516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1YTN5cEm3Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge import Rouge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7uaMAmFdAWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "461ebced-75e7-4508-fbd8-0e9f4ac9608d"
      },
      "source": [
        "!pip3 install --upgrade nltk "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.38.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=f478af2187552134eb02f15c577444d8336b48b445cc1067fb10bcae1d316e82\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtfTQ7UfdKtn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bca85f49-ac14-409d-8cd5-c1ac6cf3530f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b4cwEGWdREh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate import AlignedSent, Alignment\n",
        "from nltk.translate.meteor_score import meteor_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJpaP2BanJjH",
        "colab_type": "code",
        "outputId": "8c91a479-7758-4d97-eb0f-83d655fa94ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#print summaries generated\n",
        "print(\"Writing results to file\\n\\n\")\n",
        "fp = open(\"/content/drive/My Drive/project/average_rogue_beamserach.txt\",'w')\n",
        "\n",
        "average_rouge1=0.0\n",
        "average_rouge2=0.0\n",
        "average_rougel=0.0\n",
        "average_meteor=0.0\n",
        "n=0\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "  article= seq2text(x_val_int[i])\n",
        "\n",
        "  originalSummary = seq2summary(y_val_int[i])\n",
        " \n",
        "\n",
        "  predictedSummaryall = get_sentence(decode_sequence2(x_val_int[i].reshape(1,max_len_text)))\n",
        "  predictedSummary = predictedSummaryall[0][0]\n",
        "  \n",
        "\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(predictedSummary, originalSummary)\n",
        "  rouge_1= scores[0]['rouge-1']['f']\n",
        "  rouge_2= scores[0]['rouge-2']['f']\n",
        "  rouge_l= scores[0]['rouge-l']['f']\n",
        "  \n",
        "  average_rouge1= average_rouge1 + rouge_1\n",
        "  average_rouge2= average_rouge2 + rouge_2\n",
        "  average_rougel= average_rougel + rouge_l\n",
        "  average_meteor= round(meteor_score([originalSummary],predictedSummary ),4)\n",
        "\n",
        "  \n",
        "\n",
        "average_rouge1 = average_rouge1/n\n",
        "average_rouge2 = average_rouge2/n\n",
        "average_rougel = average_rougel/n\n",
        "average_meteor = average_meteor/n\n",
        "\n",
        "fp.write(\"\\n\\nAverage rouge 1: \"+ str(average_rouge1))\n",
        "fp.write(\"\\n\")\n",
        "fp.write(\"Average rouge 2: \" + str(average_rouge2))\n",
        "fp.write(\"\\n\")\n",
        "fp.write(\"Average rouge l: \"+ str(average_rougel))\n",
        "fp.write(\"\\n\")\n",
        "fp.write(\"Average meteor l: \"+ str(average_meteor))\n",
        "fp.write(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Average rouge 1: \"+ str(average_rouge1))\n",
        "print(\"Average rouge 2: \" + str(average_rouge2))\n",
        "print(\"Average rouge l: \"+ str(average_rougel))\n",
        "print(\"Average meteor: \"+ str(average_meteor))\n",
        "\n",
        "fp.close()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing results to file\n",
            "\n",
            "\n",
            "Average rouge 1: 0.2853363588946281\n",
            "Average rouge 2: 0.0572380905215422\n",
            "Average rouge l: 0.2528962914677641\n",
            "Average meteor: 0.2465\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}