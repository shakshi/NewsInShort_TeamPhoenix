{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gigaword_Baseline+attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05XZQDsQxrpt",
        "colab_type": "code",
        "outputId": "4095d067-c7b9-432f-e5d6-c9bc85577413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mounting google drive \n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fduWwQOpTQLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/NLP_Project')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjfo4iPp0YOP",
        "colab_type": "code",
        "outputId": "e0b77706-caa2-45a5-a77e-32f4ab6fdb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install glove-python\n",
        "# importing libraries\n",
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import sys\n",
        "import re            \n",
        "from glove import Glove\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from attention import AttentionLayer\n",
        "import warnings\n",
        "from keras import backend as K \n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/79/7e7e548dd9dcb741935d031117f4bed133276c2a047aadad42f1552d1771/glove_python-0.1.0.tar.gz (263kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 24.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 4.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove-python) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove-python) (1.4.1)\n",
            "Building wheels for collected packages: glove-python\n",
            "  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=700227 sha256=80d0314fbf8faa656b813275e22d51df8c73dd0b39d373200e3beb623728ce59\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/4b/6d/10c0d2ad32c9d9d68beec9694a6f0b6e83ab1662a90a089a4b\n",
            "Successfully built glove-python\n",
            "Installing collected packages: glove-python\n",
            "Successfully installed glove-python-0.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37NHM0e2x51X",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Reading Data** \n",
        "\n",
        "Read processed articles and summaries generated by DataProcessing.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXV5iXUSxxJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import json\n",
        "# fp= open('/content/drive/My Drive/NLP_Project/article_highlight_Sample.json', 'r')\n",
        "# content= fp.read()\n",
        "# result=json.loads(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCQ3NDZj5Nf",
        "colab_type": "code",
        "outputId": "38aa6930-3633-49e7-bfa0-0e7c6ece9672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#data after preprocessing -\n",
        "# print(\"After cleaning - \")\n",
        "# print(\"Article: \", result[str(1)][\"article\"])\n",
        "# print(\"Summary:\", result[str(1)][\"highlight\"])\n",
        "# print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After cleaning - \n",
            "Article:  associated press published 14 11 est 25 october 2013 updated 15 36 est 25 october 2013 bishop fargo catholic diocese north dakota exposed potentially hundreds church members fargo grand forks jamestown hepatitis virus late september early october state health department issued advisory exposure anyone attended five churches took communion bishop john folda pictured fargo catholic diocese north dakota exposed potentially hundreds church members fargo grand forks jamestown hepatitis state immunization program manager molly howell says risk low officials feel important alert people possible exposure diocese announced monday bishop john folda taking time diagnosed hepatitis diocese says contracted infection contaminated food attending conference newly ordained bishops italy last month symptoms hepatitis include fever tiredness loss appetite nausea abdominal discomfort fargo catholic diocese north dakota pictured bishop located\n",
            "Summary:  bishop john folda  of north dakota  is taking time off after being diagnosed   he contracted the infection through contaminated food in italy   church members in fargo  grand forks and jamestown could have been exposed   \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlsGeq9NlHc0",
        "colab_type": "text"
      },
      "source": [
        "**Data** **Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D32R61uwTM86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/gdrive/My Drive/NLP_Project/Gigaword_article_highlight_Sample.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjF-1BL6ybBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Creating dataframe\n",
        "# articles=[]\n",
        "# summaries=[]\n",
        "# d={}\n",
        "\n",
        "# for i, obj in result.items():\n",
        "#   articles.append(obj[\"article\"])\n",
        "#   summaries.append(obj[\"highlight\"])\n",
        "\n",
        "# d[\"article\"]= articles\n",
        "# d[\"summary\"]= summaries\n",
        "\n",
        "# df= pd.DataFrame.from_dict(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-APZPbMzJr3",
        "colab_type": "code",
        "outputId": "ab6ce024-c026-4b75-d710-96b283f1c13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Article</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>officials cabinet level fair trade commission ...</td>\n",
              "      <td>fair trade commission investigating consumer p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>five people killed woman gravely wounded follo...</td>\n",
              "      <td>colombian nightclub shootout leaves five dead</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>preliminary dna testing remains red army soldi...</td>\n",
              "      <td>estonia provides red army soldiers dna samples...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>transocean inc. world largest offshore drillin...</td>\n",
              "      <td>transocean globalsantafe plan to combine to cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>palestinian president mahmoud abbas make worki...</td>\n",
              "      <td>palestinian president to visit malaysia on may</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            Summary\n",
              "0           0  ...  fair trade commission investigating consumer p...\n",
              "1           1  ...      colombian nightclub shootout leaves five dead\n",
              "2           2  ...  estonia provides red army soldiers dna samples...\n",
              "3           3  ...  transocean globalsantafe plan to combine to cr...\n",
              "4           4  ...  palestinian president to visit malaysia on may   \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PnG8eLx_e9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['Summary'].apply(lambda x : \"_START_ \"+ x + \" _END_\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_xBxnxVzdmM",
        "colab_type": "text"
      },
      "source": [
        "**Counting numbers of words in articles and summaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvekGkSzLVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# word count\n",
        "for article in df['Article']:\n",
        "      article_word_count.append(len(article.split()))\n",
        "\n",
        "for summary in df['summary']:\n",
        "      summary_word_count.append(len(summary.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRZrFhYiz2zA",
        "colab_type": "code",
        "outputId": "fd158435-72e9-4080-e5b3-a7b84d0180e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "length_df = pd.DataFrame({'article':article_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBwo2u340J_R",
        "colab_type": "code",
        "outputId": "cc7604ac-56b4-4df7-a6e9-5a51a74ed272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "lengths_articles = pd.DataFrame(article_word_count, columns=['counts'])\n",
        "lengths_summaries = pd.DataFrame(summary_word_count, columns=['counts'])\n",
        "\n",
        "print(\"Articles:\")\n",
        "print(lengths_articles.describe())\n",
        "\n",
        "print(\"\\nSummaries:\")\n",
        "print(lengths_summaries.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Articles:\n",
            "             counts\n",
            "count  60000.000000\n",
            "mean      19.922083\n",
            "std        4.906283\n",
            "min        4.000000\n",
            "25%       17.000000\n",
            "50%       20.000000\n",
            "75%       23.000000\n",
            "max       64.000000\n",
            "\n",
            "Summaries:\n",
            "             counts\n",
            "count  60000.000000\n",
            "mean      10.168550\n",
            "std        2.419278\n",
            "min        4.000000\n",
            "25%        8.000000\n",
            "50%       10.000000\n",
            "75%       12.000000\n",
            "max       27.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MRNLWLvBzBt",
        "colab_type": "code",
        "outputId": "856b85b6-2670-4070-bafa-931a4a0dce6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Inspect the length of articles\n",
        "print(np.percentile(lengths_articles.counts, 90))\n",
        "print(np.percentile(lengths_articles.counts, 95))\n",
        "print(np.percentile(lengths_articles.counts, 99))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26.0\n",
            "28.0\n",
            "33.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyOdlgHDIu9",
        "colab_type": "code",
        "outputId": "b4b55744-5374-4714-ac95-010d2ec33c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Inspect the length of summaries\n",
        "print(np.percentile(lengths_summaries.counts, 90))\n",
        "print(np.percentile(lengths_summaries.counts, 95))\n",
        "print(np.percentile(lengths_summaries.counts, 99))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.0\n",
            "15.0\n",
            "17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUunmNiC2aR",
        "colab_type": "text"
      },
      "source": [
        "~90 percentile of the articles contain less than 653 words and ~90 percentile of summaries contain less than 74 words\n",
        "\n",
        "We use this data to set a reasonable value for **max_len_text** and **max_len_summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eNVt3XbC0PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text= 33\n",
        "max_len_summary= 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BtbcrknE0x7",
        "colab_type": "text"
      },
      "source": [
        "**Word Embeddings**\n",
        "\n",
        "We use pre-trained word embeddings from GLoVe \n",
        "\n",
        "These word embeddings were generated by training model on Wikipedia 2014 and Gigaword Dataset \n",
        "\n",
        "Vocabulary Size: 400,000 words \n",
        "\n",
        "Embedding vector dimension: 50\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrLfxd-1DVQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove= Glove()\n",
        "model= glove.load_stanford('/gdrive/My Drive/NLP_Project/gloveEng/glove.6B.300d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xdfjxIJtvQ3t"
      },
      "source": [
        "Printing sample word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-1ZnUSWFxKP",
        "colab_type": "code",
        "outputId": "8974c049-32f9-4cd9-e9ed-bcb208dc69d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.word_vectors[model.dictionary['woman']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.51821  , -0.13809  , -0.41185  , -0.13133  ,  0.0035659,\n",
              "       -0.31205  , -0.31242  , -0.43538  , -0.27017  , -1.1338   ,\n",
              "        0.19282  , -0.23786  ,  0.0028892, -0.027078 ,  0.14747  ,\n",
              "       -0.051265 ,  0.089021 , -0.12337  , -0.40892  , -0.39197  ,\n",
              "       -0.5665   ,  0.40684  , -0.057313 ,  0.18613  , -0.33095  ,\n",
              "       -0.25243  ,  0.33452  , -0.23104  , -0.0099149,  0.24269  ,\n",
              "       -0.57504  ,  0.30122  , -0.33779  , -0.294    , -0.80202  ,\n",
              "        0.44674  , -0.40296  , -0.21026  ,  0.1072   ,  0.53937  ,\n",
              "        0.63971  , -0.3154   , -0.082537 , -0.038314 , -0.058821 ,\n",
              "        0.11235  ,  0.50928  ,  0.14656  , -0.18988  ,  0.24132  ,\n",
              "       -0.038442 ,  0.071418 ,  0.38471  ,  0.10584  , -0.52786  ,\n",
              "       -0.057574 ,  0.13771  , -0.48613  ,  0.62553  , -0.3308   ,\n",
              "       -0.065539 ,  0.1791   ,  0.62746  ,  0.087208 , -0.60422  ,\n",
              "       -0.64595  , -0.2389   , -0.1585   , -0.07948  , -0.037848 ,\n",
              "       -0.205    , -0.44504  , -0.21127  , -0.0026664, -0.0080152,\n",
              "        0.39607  ,  0.069091 , -0.34379  , -0.13992  ,  0.084029 ,\n",
              "       -0.40245  ,  0.094426 ,  0.28908  ,  0.6216   , -0.4132   ,\n",
              "       -0.12153  , -0.40676  , -0.05771  ,  0.17415  ,  0.094069 ,\n",
              "       -0.65955  , -0.34154  , -0.079291 ,  0.16867  ,  0.31665  ,\n",
              "       -0.072868 , -0.44181  , -0.19555  ,  0.16942  , -0.197    ,\n",
              "        0.17484  ,  0.11972  ,  0.012957 , -0.32238  ,  0.33737  ,\n",
              "        0.35553  ,  0.82906  , -0.37521  ,  0.34777  , -0.13105  ,\n",
              "       -0.046688 ,  1.2125   ,  0.025435 , -0.36021  ,  0.65259  ,\n",
              "        0.63729  ,  0.23457  ,  0.19874  ,  0.22589  , -0.016769 ,\n",
              "        0.10671  ,  0.86805  , -0.02853  , -0.011634 , -0.39911  ,\n",
              "        0.12429  , -0.066363 ,  0.0080237,  0.41826  , -0.60603  ,\n",
              "        0.26269  ,  0.035625 , -0.10225  ,  0.44362  , -0.38952  ,\n",
              "       -0.054241 , -0.31542  , -0.076452 , -0.33072  ,  0.42178  ,\n",
              "        0.29242  ,  0.13222  , -0.14896  ,  0.32047  , -0.4735   ,\n",
              "       -0.1093   ,  0.31163  ,  0.49836  , -0.20143  ,  0.36058  ,\n",
              "        0.32242  , -0.11148  ,  0.6416   ,  0.20955  ,  0.035183 ,\n",
              "        0.16684  , -0.41427  , -0.41894  ,  0.18777  ,  0.39424  ,\n",
              "        0.25784  ,  0.18818  ,  0.60567  ,  0.15537  , -0.27121  ,\n",
              "        0.054047 , -0.18342  ,  0.29789  ,  0.35805  , -0.40148  ,\n",
              "       -0.019914 , -0.019742 , -0.56609  , -0.25878  , -0.036075 ,\n",
              "        0.0093725, -0.25284  , -0.061715 , -0.26441  ,  0.47597  ,\n",
              "        0.087956 ,  0.051997 ,  0.21366  , -0.0034455,  0.1739   ,\n",
              "       -0.16853  , -0.22233  , -0.1006   , -0.032696 , -0.008549 ,\n",
              "        0.036532 , -0.19339  , -0.28571  , -0.29294  , -0.53655  ,\n",
              "        0.16387  , -0.36861  , -0.52443  , -0.84287  ,  0.26247  ,\n",
              "        1.8261   ,  0.029467 ,  0.19155  ,  0.28406  , -0.1017   ,\n",
              "       -0.31416  , -0.084328 ,  0.42934  ,  0.32851  ,  0.41274  ,\n",
              "       -0.080323 ,  0.063666 , -0.18441  ,  0.13328  ,  0.46     ,\n",
              "       -0.24984  ,  0.12574  , -0.49056  , -0.072603 ,  0.28191  ,\n",
              "       -0.25738  ,  0.40629  ,  0.38381  , -0.37685  , -0.16371  ,\n",
              "        0.30354  , -0.38234  , -0.61633  , -0.22076  ,  0.38153  ,\n",
              "        0.54091  , -0.32349  , -0.032075 , -0.051326 , -0.12465  ,\n",
              "        0.19237  , -0.077144 ,  0.27005  , -0.20103  , -0.26512  ,\n",
              "        0.35769  , -0.23437  ,  0.054273 ,  0.16901  , -0.15758  ,\n",
              "        0.42714  ,  0.23167  , -0.021318 ,  0.3086   ,  0.44873  ,\n",
              "       -0.12432  , -0.15715  , -0.099448 , -0.24825  ,  1.156    ,\n",
              "       -0.38925  , -0.0063171,  0.48928  ,  0.46089  , -0.17058  ,\n",
              "        0.06118  , -0.54     , -0.054482 ,  0.13329  , -0.47944  ,\n",
              "        0.17119  ,  0.26289  ,  0.14383  , -0.30443  ,  0.27534  ,\n",
              "       -0.14711  , -0.52172  ,  0.32909  , -0.15149  ,  0.1539   ,\n",
              "        0.24171  , -1.6971   ,  0.027579 , -0.0073776,  0.30144  ,\n",
              "        0.011751 ,  0.012419 ,  0.38711  , -0.044167 , -0.62495  ,\n",
              "        0.74536  ,  0.043054 ,  0.62925  , -0.33381  , -0.048651 ,\n",
              "        0.09395  , -0.20336  , -0.055232 ,  0.096572 ,  0.09321  ,\n",
              "       -0.17298  , -0.20794  ,  0.37342  , -0.030166 ,  0.73014  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytj57gjKFx5e",
        "colab_type": "text"
      },
      "source": [
        "Printing words with similar word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-9uyUw0Fl_H",
        "colab_type": "code",
        "outputId": "14be92fb-04a8-46b2-8395-f4cbbcfd1447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.most_similar('woman'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('girl', 0.7296419112178933), ('man', 0.6998663379619018), ('mother', 0.6899437807604597), ('she', 0.6433226707219909)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5tomJTF7OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating embedding dictionary\n",
        "embeddings_index = {}\n",
        "\n",
        "for word in model.dictionary:\n",
        "  embedding = model.word_vectors[model.dictionary[word]]\n",
        "  embeddings_index[word] = embedding\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9RDilvsTG8M",
        "colab_type": "code",
        "outputId": "14b4a767-c534-45d6-b754-744a60938edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embeddings_index[\"the\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCll6PHIKdf",
        "colab_type": "text"
      },
      "source": [
        "**Split Data for training and testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHQMc3hXITWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr,x_test,y_tr,y_test = train_test_split(df['Article'],df['summary'],test_size=0.1,random_state=0,shuffle=True) \n",
        "\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_tr,y_tr,test_size=0.1,random_state=0,shuffle=True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqdTIfa3IfO-",
        "colab_type": "code",
        "outputId": "e597ca19-a6e0-44a2-f937-b149c712a901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Training data: ', len(x_tr))\n",
        "print('Validation data: ', len(x_val))\n",
        "print('Testing data:', len(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data:  48600\n",
            "Validation data:  5400\n",
            "Testing data: 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRaE1uMG4Ta",
        "colab_type": "text"
      },
      "source": [
        "**Tokenize Data, create vocabulary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6SBJcSeFEbI",
        "colab_type": "text"
      },
      "source": [
        "Article Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMzGnpCWGTqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "before_sample=x_tr[0]\n",
        "# Tokenizer library in keras that maps words to integers, integers to words\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "# padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "after_sample=x_tr[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJwKzOyPXzsu",
        "colab_type": "code",
        "outputId": "02694928-d907-484a-d731-e4f2df8f156e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"Aricle Before: \\n\"+str(before_sample[0:250]))\n",
        "print()\n",
        "print(\"Article After: \\n\"+str(after_sample[0:250]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aricle Before: \n",
            "officials cabinet level fair trade commission lrb ftc rrb said friday formed ad hoc group investigate whether manipulation commodity prices traders local market .\n",
            "\n",
            "Article After: \n",
            "[ 243  139 3319    2  304 2550 1644 1208 1869  502 2106  245  304  410\n",
            "  154   29 1528  331   66 1033 1705  113    1 2686    3   29  140  945\n",
            "  606    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_PAIkNFFJcL",
        "colab_type": "text"
      },
      "source": [
        "Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JnZ-NWpIw55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\n",
        "\n",
        "# same for summaries\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35pJdzPBJPEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding matrix to be used in model\n",
        "embedding_dim= 300\n",
        "\n",
        "x_embedding_matrix= np.zeros((x_voc_size, embedding_dim))\n",
        "\n",
        "for word, i in x_tokenizer.word_index.items():\n",
        "  if i> x_voc_size:\n",
        "    continue\n",
        "  embedding_vector= embeddings_index.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    x_embedding_matrix[i]= embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7o-zYmt8fgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding matrix for decoder to be used in model\n",
        "y_embedding_matrix= np.zeros((y_voc_size, embedding_dim))\n",
        "\n",
        "for word, i in y_tokenizer.word_index.items():\n",
        "  if i> y_voc_size:\n",
        "    continue\n",
        "  embedding_vector= embeddings_index.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    y_embedding_matrix[i]= embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDWOd3xKKtCH",
        "colab_type": "code",
        "outputId": "a8c11648-bfc9-4985-8a83-e420103068cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_embedding_matrix.shape)\n",
        "print(y_embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40792, 300)\n",
            "(24277, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBuOp5O5Jv9U",
        "colab_type": "text"
      },
      "source": [
        "**Build Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsgqP2ELAW0",
        "colab_type": "code",
        "outputId": "b8750f0e-6c9b-4534-95d7-4a5481816199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "latent_dim = 300 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,embeddings_initializer= Constant(x_embedding_matrix), trainable=False)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_output1, forward_h, forward_c, backward_h, backward_c = encoder_lstm1(enc_emb)\n",
        "\"\"\"\n",
        "state_h1 = Concatenate()([forward_h, backward_h])\n",
        "state_c1 = Concatenate()([forward_c, backward_c])\n",
        "encoder_states = [state_h1, state_c1]\n",
        "\"\"\"\n",
        "#LSTM 2 \n",
        "# encoder output 1 is fed as input to the next lstm\n",
        "encoder_lstm2 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_output2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_lstm2(encoder_output1)\n",
        "\"\"\"\n",
        "state_h2 = Concatenate()([forward_h2, backward_h2])\n",
        "state_c2 = Concatenate()([forward_c2, backward_c2])\n",
        "encoder_states = [state_h2, state_c2]\n",
        "#encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\"\"\"\n",
        "#LSTM 3 \n",
        "# encoder output 2 fed as input to next lstm \n",
        "encoder_lstm3=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\n",
        "encoder_output3, forward_h3, forward_c3, backward_h3, backward_c3 = encoder_lstm3(encoder_output2)\n",
        "\"\"\"\n",
        "state_h3 = Concatenate()([forward_h3, backward_h3])\n",
        "state_c3 = Concatenate()([forward_c3, backward_c3])\n",
        "encoder_states3 = [state_h3, state_c3]\n",
        "#encoder_output3, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\"\"\"\n",
        "#LSTM 4\n",
        "encoder_lstm4=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\n",
        "encoder_outputs, forward_h4, forward_c4, backward_h4, backward_c4 = encoder_lstm2(encoder_output3)\n",
        "state_h = Concatenate()([forward_h4, backward_h4])\n",
        "state_c = Concatenate()([forward_c4, backward_c4])\n",
        "encoder_states = [state_h, state_c]\n",
        "print(state_h.shape)\n",
        "print(state_c.shape)\n",
        "#encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 600)\n",
            "(None, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do2w6u4s8y3F",
        "colab_type": "code",
        "outputId": "58eddd94-d450-4461-fff7-390c4ca9561c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer=  Embedding(y_voc_size, latent_dim,embeddings_initializer= Constant(y_embedding_matrix), trainable=False)\n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM1\n",
        "# Using encoder_states as decoder's initial state\n",
        "decoder_lstm1 = LSTM(2*latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm1(dec_emb,initial_state=encoder_states) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7fe24b9f8c88>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7fe24b9f8c88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7fe24b9f8c88>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method AttentionLayer.call of <attention.AttentionLayer object at 0x7fe24b9f8c88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBsJUdy1YZDp",
        "colab_type": "code",
        "outputId": "979627d5-70a3-4dbf-8292-e95886b9680d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 5198644503774624869\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 3256129796683126582\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 7712939936977623283\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15701463552\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 6203480386392498484\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1fLcgt9MAxM",
        "colab_type": "code",
        "outputId": "7e194516-ce9c-4203-9ee6-e95e3f89ff75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# early stopping \n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 33)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 33, 300)      12237600    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 33, 600), (N 1442400     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 33, 600), (N 2162400     bidirectional[0][0]              \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 33, 600), (N 2162400     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    7283100     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 600)          0           bidirectional_1[1][1]            \n",
            "                                                                 bidirectional_1[1][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           bidirectional_1[1][2]            \n",
            "                                                                 bidirectional_1[1][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 600),  2162400     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 600),  720600      bidirectional_1[1][0]            \n",
            "                                                                 lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1200)   0           lstm_4[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 24277)  29156677    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 57,327,577\n",
            "Trainable params: 37,806,877\n",
            "Non-trainable params: 19,520,700\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuxX57LSMnpF",
        "colab_type": "code",
        "outputId": "8c01c79a-00e0-42e6-a33c-d3817f248d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=8,batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]),callbacks = [es])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "380/380 [==============================] - 217s 572ms/step - loss: 4.4469 - val_loss: 3.8399\n",
            "Epoch 2/8\n",
            "380/380 [==============================] - 217s 570ms/step - loss: 3.8045 - val_loss: 3.5300\n",
            "Epoch 3/8\n",
            "380/380 [==============================] - 216s 567ms/step - loss: 3.4882 - val_loss: 3.3750\n",
            "Epoch 4/8\n",
            "380/380 [==============================] - 216s 568ms/step - loss: 3.2610 - val_loss: 3.3002\n",
            "Epoch 5/8\n",
            "380/380 [==============================] - 216s 568ms/step - loss: 3.0706 - val_loss: 3.2606\n",
            "Epoch 6/8\n",
            "380/380 [==============================] - 216s 569ms/step - loss: 2.8914 - val_loss: 3.2317\n",
            "Epoch 7/8\n",
            "380/380 [==============================] - 216s 568ms/step - loss: 2.7174 - val_loss: 3.2451\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2zyE5AzM_R7",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation error to check over-fitting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJ9dxGoM7vE",
        "colab_type": "code",
        "outputId": "749fa08e-5f5f-4fec-cdb0-b4e51d15867d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='val') \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H6r6c2I14JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "#model = load_model('/content/drive/My Drive/my_model3.h5',custom_objects={'AttentionLayer': AttentionLayer})\n",
        "model.save('/gdrive/My Drive/NLP_Project/gigaword_baseline_attn.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#path = '/content/drive/My Drive/my_model4.h5'\n",
        "#model.save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2yH4JhmGV8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUz8-xOVGWQg",
        "colab_type": "code",
        "outputId": "dcef227c-6046-43f1-dae9-29576a32cbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(reverse_source_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40791"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmV89Pg_wzis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "#2 ideas : threshold value if less, remove and if end token found, remove and store in another list and then merge at the end\n",
        "\n",
        "def beam_search(encoder_model,decoder_model, src_input, k, sequence_max_len):\n",
        "\n",
        "    e_out, e_h, e_c = encoder_model.predict(src_input)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    start = True\n",
        "    \n",
        "    #print(k_beam)\n",
        "    # l : point on target sentence to predict\n",
        "    all_k_beams = [[[],1]]\n",
        "    load_hidden={}\n",
        "    end_sentence = []\n",
        "    for l in range(sequence_max_len):\n",
        "\n",
        "        if(start==True):\n",
        "\n",
        "          start=False\n",
        "          output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "          possible_k = output_tokens[0, -1, :].argsort()[-k:][::-1]\n",
        "          #print(\"Possible k in start: \"+str((possible_k)))\n",
        "          dummy_list = []\n",
        "          begin=True\n",
        "          for cand in all_k_beams:\n",
        "            \n",
        "            for curr_k in possible_k:\n",
        "              #print(\"Cand: \"+str(cand)+\" curr_k: \"+str(curr_k))\n",
        "              #print(cand[0]+[curr_k])\n",
        "              #print(cand[1]+np.log(output_tokens[0, -1, :][curr_k]))\n",
        "              curr = [cand[0]+[curr_k],cand[1]-np.log(output_tokens[0, -1, :][curr_k])]\n",
        "              \n",
        "              dummy_list.append(curr)\n",
        "              if(begin==True):\n",
        "                #target_seq = np.zeros((1,1))\n",
        "                #target_seq[0, 0] = curr_k\n",
        "                load_hidden[curr_k] = [h,c]\n",
        "            begin=False\n",
        "          all_k_beams = dummy_list[:]\n",
        "          #print(all_k_beams)\n",
        "          prev_target_seq = copy.deepcopy(possible_k)\n",
        "          #print(\"load_hidden: \"+str(load_hidden.keys()))\n",
        "        else:\n",
        "          #print(\"l is: \"+str(l))\n",
        "          #print(\"In else, prev target seq: \"+str(prev_target_seq))\n",
        "          for target_seq1 in prev_target_seq:\n",
        "            #print(\"Prev index: \"+str(target_seq1))\n",
        "            target_seq = np.zeros((1,1))\n",
        "            target_seq[0, 0] = target_seq1\n",
        "\n",
        "            output_tokens, h, c = decoder_model.predict([target_seq] + [e_out,load_hidden[target_seq1][0],load_hidden[target_seq1][1]])\n",
        "\n",
        "            possible_k = output_tokens[0, -1, :].argsort()[-k:][::-1]\n",
        "            #print(\"Possible k not in start: \"+str((possible_k)))\n",
        "\n",
        "            dummy_list = []\n",
        "            begin = True\n",
        "            for cand in all_k_beams:\n",
        "              for curr_k in possible_k:\n",
        "                if(cand[0][-1]==target_seq1 and len(cand[0])==l):\n",
        "                  #print(\"Here I am\")\n",
        "                  #print(\"Looking at cand: \"+str(cand[0]))\n",
        "                  ended=False\n",
        "                  curr = [cand[0]+[curr_k],cand[1]-np.log(output_tokens[0, -1, :][curr_k])]\n",
        "                  if(curr_k in reverse_target_word_index):\n",
        "                    sampled_token = reverse_target_word_index[curr_k]\n",
        "                    if(sampled_token=='end'):\n",
        "                      end_sentence.append(curr)\n",
        "                      ended=True\n",
        "                  if(ended==False):\n",
        "                    dummy_list.append(curr)\n",
        "                if(begin==True):\n",
        "                  #target_seq = np.zeros((1,1))\n",
        "                  #target_seq[0, 0] = curr_k\n",
        "                  load_hidden[curr_k] = [h,c]\n",
        "              begin=False\n",
        "            all_k_beams +=dummy_list\n",
        "            #print(all_k_beams)\n",
        "            prev_target_seq = copy.deepcopy(possible_k)\n",
        "        \n",
        "        # top k\n",
        "    #print(end_sentence)\n",
        "    all_k_beams += end_sentence\n",
        "    all_k_beams.sort(key=lambda r:r[1])\n",
        "    k_beam = all_k_beams[-k:]\n",
        "    #k_beam = k_beam[::-1]\n",
        "    return k_beam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ5EFfq7GWeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference Phase \n",
        "\n",
        "\"\"\"\n",
        "After training, the model is tested on new source sequences\n",
        "for which the target sequence is not known \n",
        "setting up inference architecture for it \n",
        "\"\"\"\n",
        "\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(2*latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(2*latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim*2))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm1(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\"\"\"\n",
        "decoder_outputs3, state_h2, state_c2 = decoder_lstm2(decoder_outputs2)\n",
        "decoder_outputs4, state_h2, state_c2 = decoder_lstm3(decoder_outputs3)\n",
        "decoder_outputs5, state_h2, state_c2 = decoder_lstm4(decoder_outputs4)\n",
        "\"\"\"\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs] + [state_h2, state_c2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x9fXLd1jJSpm",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq, search_strat):\n",
        "    # Encode the input as state vectors.\n",
        "\n",
        "    if(search_strat ==\"Beam\"):\n",
        "      decoded_sentence = beam_search(encoder_model,decoder_model, input_seq, 3, 50)\n",
        "    else:\n",
        "      e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "      # Generate empty target sequence of length 1.\n",
        "      target_seq = np.zeros((1,1))\n",
        "\n",
        "      # Chose the 'start' word as the first word of the target sequence\n",
        "      target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "      stop_condition = False\n",
        "      decoded_sentence = ''\n",
        "      \n",
        "      while not stop_condition:\n",
        "          output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "          # Sample a token\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "          if sampled_token_index in reverse_target_word_index:\n",
        "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "          else:\n",
        "            sampled_token=\"UNK\"\n",
        "            \n",
        "          if(sampled_token!='end'):\n",
        "              decoded_sentence += ' '+sampled_token\n",
        "\n",
        "          # Exit condition: either hit max length or find stop word.\n",
        "          if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "              stop_condition = True\n",
        "\n",
        "          # Update the target sequence (of length 1).\n",
        "          target_seq = np.zeros((1,1))\n",
        "          target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "          # Update internal states\n",
        "          e_h, e_c = h, c\n",
        "    \n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k00oOQOQGqSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCyB3qx5b22r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentence(model_summary):\n",
        "  all_Sentence = []\n",
        "  for int_sent in model_summary:\n",
        "    sent = int_sent[0]\n",
        "    decoded_sentence= ''\n",
        "    for sampled_token_index in sent:\n",
        "      if sampled_token_index in reverse_target_word_index:\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "      else:\n",
        "        sampled_token=\"UNK\"\n",
        "            \n",
        "      if(sampled_token!='end'):\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else:\n",
        "        print(\"broken\")\n",
        "        break\n",
        "    #print(str(decoded_sentence)+ \" , \"+str(int_sent[1]))\n",
        "    all_Sentence.append([decoded_sentence,int_sent[1]])\n",
        "  return all_Sentence \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCRO64l4BSNa",
        "colab_type": "code",
        "outputId": "0eef9d9d-dc57-4426-dc91-a6c4948ea076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "refrence_summary = seq2summary(y_tr[4])\n",
        "search_strat = \"Greedy\" #\"Beam\"\n",
        "model_summary = decode_sequence(x_tr[4].reshape(1,max_len_text),search_strat)\n",
        "\n",
        "print(\"Reference summary: \"+str(refrence_summary))\n",
        "if(search_strat==\"Greedy\"):\n",
        "  print(\"Predicted summary: \"+str(model_summary))\n",
        "else:\n",
        "  all_s=get_sentence(model_summary)\n",
        "  for pred_s in all_s:\n",
        "    print(\"Predicted summary: \"+str(pred_s))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reference summary: basque separatists cease fire warn of violence \n",
            "Predicted summary:  basque separatists in eta to be cease fire\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r957VgvFMS94",
        "colab_type": "code",
        "outputId": "239a4b84-e956-44a1-e83e-88a7090a5d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK39b5Ym5Hyt",
        "colab_type": "code",
        "outputId": "5566beb9-d2f3-45c8-f9bd-bf20a5918e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Writing results to file\")\n",
        "fp = open(\"/gdrive/My Drive/NLP_Project/Gigaword_Model_summaries_baseline_plus_attention_try_3.txt\",'w')\n",
        "for i in range(500):\n",
        "  fp.write(\"Article:\" + seq2text(x_val[i]))\n",
        "  originalSummary = seq2summary(y_val[i])\n",
        "  fp.write(\"\\nOriginal summary:\" + originalSummary)\n",
        "  predictedSummary = decode_sequence(x_val[i].reshape(1,max_len_text),\"greedy\")\n",
        "  fp.write(\"\\nPredicted summary:\" + predictedSummary)\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(predictedSummary, originalSummary) \n",
        "  fp.write(str(scores[0]['rouge-1']['f']))\n",
        "  fp.write(str(scores[0]['rouge-l']['f']))\n",
        "  fp.write(\"\\n\")\n",
        "fp.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing results to file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p4xBdoRLhQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp= open('/content/drive/My Drive/NLP_Project/Gigaword_Model_summaries_baseline_plus_attention.txt', 'r')\n",
        "content= fp.readlines()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh3dQC0O_gGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = {}\n",
        "pos =0\n",
        "while(pos < len(content)):\n",
        "  article = content[pos].split(\":\")\n",
        "  value = {}\n",
        "  results[article[1].rstrip()] = value\n",
        "  pos += 1\n",
        "  orig = content[pos].split(\":\")\n",
        "  value[\"original\"] = orig[1].rstrip()\n",
        "  pos += 1\n",
        "  pred = content[pos].split(\":\")\n",
        "  second = pred[1]\n",
        "  important = second.split('0')\n",
        "  value[\"predicted\"] = important[0].rstrip()\n",
        "  pos += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUgnA0NM_omt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-q7tHWZ_opz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e9904d45-d7eb-4ccd-8a59-a83de6a9b0d6"
      },
      "source": [
        "count = len(results)\n",
        "sum_rouge_1 =0\n",
        "sum_rouge_2 =0\n",
        "sum_rouge_lcs =0\n",
        "highest_rouge_1 =0\n",
        "highest_rouge_2 =0\n",
        "highest_rouge_lcs =0\n",
        "from rouge import Rouge \n",
        "for key in results:\n",
        "  value = results[key]\n",
        "  rouge = Rouge()\n",
        "  # print(value[\"predicted\"])\n",
        "  # print(value[\"original\"])\n",
        "  scores = rouge.get_scores(value[\"predicted\"], value[\"original\"])\n",
        "  # print(scores)\n",
        "  sum_rouge_1 += scores[0]['rouge-1']['f']\n",
        "  sum_rouge_2 += scores[0]['rouge-2']['f']\n",
        "  sum_rouge_lcs += scores[0]['rouge-l']['f']\n",
        "  if(scores[0]['rouge-1']['f'] > highest_rouge_1):\n",
        "    highest_rouge_1  = scores[0]['rouge-1']['f']\n",
        "  if(scores[0]['rouge-2']['f'] > highest_rouge_2):\n",
        "    highest_rouge_2  = scores[0]['rouge-2']['f']\n",
        "  if(scores[0]['rouge-l']['f'] > highest_rouge_lcs):\n",
        "    highest_rouge_lcs  = scores[0]['rouge-l']['f']\n",
        "\n",
        "average_rouge_1 = sum_rouge_1/count\n",
        "average_rouge_2 = sum_rouge_2/count\n",
        "average_rouge_lcs = sum_rouge_lcs/count\n",
        "print(\"Average rouge 1 Score : \" + str(average_rouge_1))\n",
        "print(\"Average rouge 2 Score : \" + str(average_rouge_2))\n",
        "print(\"Average rouge lcs Score : \" + str(average_rouge_lcs))\n",
        "print(\"\\n\")\n",
        "print(\"Highest Rouge 1 score : \" + str(highest_rouge_1))\n",
        "print(\"Highest Rouge 2 score : \" + str(highest_rouge_2))\n",
        "print(\"Highest Rouge lcs score : \" + str(highest_rouge_lcs))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average rouge 1 Score : 0.2301\n",
            "Average rouge 2 Score : 0.4555\n",
            "Average rouge lcs Score : 0.1621\n",
            "\n",
            "\n",
            "Highest Rouge 1 score : 0.9999\n",
            "Highest Rouge 2 score : 0.9999\n",
            "Highest Rouge lcs score : 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFpZ39X2BAPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install --upgrade nltk \n",
        "from nltk.translate import AlignedSent, Alignment\n",
        "from nltk.translate.meteor_score import meteor_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R47dFrCiBY2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C3TPmsPBcHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content= fp.readlines()\n",
        "references_english = []\n",
        "predicted_english = []\n",
        "pos =0\n",
        "while(pos < len(content)):\n",
        "  pos += 2\n",
        "  orig = content[pos].split(\":\")\n",
        "  references_english.append(orig[1])\n",
        "  pos += 1\n",
        "  pred = content[pos].split(\":\")\n",
        "  predicted_english.append(pred[1])\n",
        "  pos += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFwrlpIhCBgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4de34ce2-45cf-4d20-f5a3-f4981fa58965"
      },
      "source": [
        "total_meteor = 0.0\n",
        "n = 0 \n",
        "for i in range(len(references_english)):\n",
        "  total_meteor += round(meteor_score([references_english[i]], predicted_english[i]),4)\n",
        "  n+=1\n",
        "print(\"Average score\")\n",
        "print(\"\\n\")\n",
        "print(total_meteor/n)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average score\n",
            "\n",
            "\n",
            "18.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hoxW8hGCTpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}