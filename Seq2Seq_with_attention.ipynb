{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline+attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05XZQDsQxrpt",
        "colab_type": "code",
        "outputId": "94037c02-79e2-4e34-e4dc-6b92dbc51e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mounting google drive \n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fduWwQOpTQLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/NLP- News summary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjfo4iPp0YOP",
        "colab_type": "code",
        "outputId": "3971002e-e1d1-433f-e26e-8fed4f0f94a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install glove-python\n",
        "# importing libraries\n",
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import sys\n",
        "import re            \n",
        "from glove import Glove\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from attention import AttentionLayer\n",
        "import warnings\n",
        "from keras import backend as K \n",
        "from keras.initializers import Constant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: glove-python in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove-python) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove-python) (1.4.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37NHM0e2x51X",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Reading Data** \n",
        "\n",
        "Read processed articles and summaries generated by DataProcessing.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXV5iXUSxxJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "fp= open('/content/drive/My Drive/article_highlight_Sample.json', 'r')\n",
        "content= fp.read()\n",
        "result=json.loads(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCQ3NDZj5Nf",
        "colab_type": "code",
        "outputId": "1c94d63f-9ce3-4bbc-c84a-11b82943443e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#data after preprocessing -\n",
        "print(\"After cleaning - \")\n",
        "print(\"Article: \", result[str(1)][\"article\"])\n",
        "print(\"Summary:\", result[str(1)][\"highlight\"])\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After cleaning - \n",
            "Article:  associated press published 14 11 est 25 october 2013 updated 15 36 est 25 october 2013 bishop fargo catholic diocese north dakota exposed potentially hundreds church members fargo grand forks jamestown hepatitis virus late september early october state health department issued advisory exposure anyone attended five churches took communion bishop john folda pictured fargo catholic diocese north dakota exposed potentially hundreds church members fargo grand forks jamestown hepatitis state immunization program manager molly howell says risk low officials feel important alert people possible exposure diocese announced monday bishop john folda taking time diagnosed hepatitis diocese says contracted infection contaminated food attending conference newly ordained bishops italy last month symptoms hepatitis include fever tiredness loss appetite nausea abdominal discomfort fargo catholic diocese north dakota pictured bishop located\n",
            "Summary:  bishop john folda  of north dakota  is taking time off after being diagnosed   he contracted the infection through contaminated food in italy   church members in fargo  grand forks and jamestown could have been exposed   \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlsGeq9NlHc0",
        "colab_type": "text"
      },
      "source": [
        "**Data** **Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjF-1BL6ybBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating dataframe\n",
        "articles=[]\n",
        "summaries=[]\n",
        "d={}\n",
        "\n",
        "for i, obj in result.items():\n",
        "  articles.append(obj[\"article\"])\n",
        "  summaries.append(obj[\"highlight\"])\n",
        "\n",
        "d[\"article\"]= articles\n",
        "d[\"summary\"]= summaries\n",
        "\n",
        "df= pd.DataFrame.from_dict(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-APZPbMzJr3",
        "colab_type": "code",
        "outputId": "1e84e0e9-689c-4143-f889-170d22a6184a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>associated press published 14 11 est 25 octobe...</td>\n",
              "      <td>bishop john folda  of north dakota  is taking...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ralph mata internal affairs lieutenant miami d...</td>\n",
              "      <td>criminal complaint  cop used his role to help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drunk driver killed young woman head crash che...</td>\n",
              "      <td>craig eccleston todd  27  had drunk at least ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>breezy sweep pen president vladimir putin wrot...</td>\n",
              "      <td>nina dos santos says europe must be ready to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>leetwood team still 100 record sky bet league ...</td>\n",
              "      <td>fleetwood top of league one after 2 0 win at ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             article                                            summary\n",
              "0  associated press published 14 11 est 25 octobe...   bishop john folda  of north dakota  is taking...\n",
              "1  ralph mata internal affairs lieutenant miami d...   criminal complaint  cop used his role to help...\n",
              "2  drunk driver killed young woman head crash che...   craig eccleston todd  27  had drunk at least ...\n",
              "3  breezy sweep pen president vladimir putin wrot...   nina dos santos says europe must be ready to ...\n",
              "4  leetwood team still 100 record sky bet league ...   fleetwood top of league one after 2 0 win at ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PnG8eLx_e9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : \"_START_ \"+ x + \" _END_\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_xBxnxVzdmM",
        "colab_type": "text"
      },
      "source": [
        "**Counting numbers of words in articles and summaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzvekGkSzLVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# word count\n",
        "for article in df['article']:\n",
        "      article_word_count.append(len(article.split()))\n",
        "\n",
        "for summary in df['summary']:\n",
        "      summary_word_count.append(len(summary.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRZrFhYiz2zA",
        "colab_type": "code",
        "outputId": "119a7abf-141e-4ef5-bc62-045576d73ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "length_df = pd.DataFrame({'article':article_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBwo2u340J_R",
        "colab_type": "code",
        "outputId": "25b253d7-2e76-42fc-8f4b-0e9c0ceb0c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "lengths_articles = pd.DataFrame(article_word_count, columns=['counts'])\n",
        "lengths_summaries = pd.DataFrame(summary_word_count, columns=['counts'])\n",
        "\n",
        "print(\"Articles:\")\n",
        "print(lengths_articles.describe())\n",
        "\n",
        "print(\"\\nSummaries:\")\n",
        "print(lengths_summaries.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Articles:\n",
            "             counts\n",
            "count  60000.000000\n",
            "mean     393.090717\n",
            "std      187.290512\n",
            "min       13.000000\n",
            "25%      256.000000\n",
            "50%      359.000000\n",
            "75%      495.000000\n",
            "max     2000.000000\n",
            "\n",
            "Summaries:\n",
            "             counts\n",
            "count  60000.000000\n",
            "mean      51.357567\n",
            "std       20.961405\n",
            "min        8.000000\n",
            "25%       38.000000\n",
            "50%       48.000000\n",
            "75%       59.000000\n",
            "max     1247.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MRNLWLvBzBt",
        "colab_type": "code",
        "outputId": "120ee1a8-4dbe-4786-ba85-6573608464a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Inspect the length of articles\n",
        "print(np.percentile(lengths_articles.counts, 90))\n",
        "print(np.percentile(lengths_articles.counts, 95))\n",
        "print(np.percentile(lengths_articles.counts, 99))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "653.0\n",
            "763.0\n",
            "945.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjyOdlgHDIu9",
        "colab_type": "code",
        "outputId": "cf4ac593-046e-4de9-fc5f-e82e53365d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Inspect the length of summaries\n",
        "print(np.percentile(lengths_summaries.counts, 90))\n",
        "print(np.percentile(lengths_summaries.counts, 95))\n",
        "print(np.percentile(lengths_summaries.counts, 99))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.0\n",
            "88.0\n",
            "117.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUunmNiC2aR",
        "colab_type": "text"
      },
      "source": [
        "~90 percentile of the articles contain less than 653 words and ~90 percentile of summaries contain less than 74 words\n",
        "\n",
        "We use this data to set a reasonable value for **max_len_text** and **max_len_summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eNVt3XbC0PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text= 100\n",
        "max_len_summary= 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BtbcrknE0x7",
        "colab_type": "text"
      },
      "source": [
        "**Word Embeddings**\n",
        "\n",
        "We use pre-trained word embeddings from GLoVe \n",
        "\n",
        "These word embeddings were generated by training model on Wikipedia 2014 and Gigaword Dataset \n",
        "\n",
        "Vocabulary Size: 400,000 words \n",
        "\n",
        "Embedding vector dimension: 50\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrLfxd-1DVQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove= Glove()\n",
        "model= glove.load_stanford('/content/drive/My Drive/NLP- News summary/gloveEng/glove.6B.300d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xdfjxIJtvQ3t"
      },
      "source": [
        "Printing sample word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-1ZnUSWFxKP",
        "colab_type": "code",
        "outputId": "6e88121e-aa70-41b7-8057-513480ba971a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.word_vectors[model.dictionary['woman']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.51821  , -0.13809  , -0.41185  , -0.13133  ,  0.0035659,\n",
              "       -0.31205  , -0.31242  , -0.43538  , -0.27017  , -1.1338   ,\n",
              "        0.19282  , -0.23786  ,  0.0028892, -0.027078 ,  0.14747  ,\n",
              "       -0.051265 ,  0.089021 , -0.12337  , -0.40892  , -0.39197  ,\n",
              "       -0.5665   ,  0.40684  , -0.057313 ,  0.18613  , -0.33095  ,\n",
              "       -0.25243  ,  0.33452  , -0.23104  , -0.0099149,  0.24269  ,\n",
              "       -0.57504  ,  0.30122  , -0.33779  , -0.294    , -0.80202  ,\n",
              "        0.44674  , -0.40296  , -0.21026  ,  0.1072   ,  0.53937  ,\n",
              "        0.63971  , -0.3154   , -0.082537 , -0.038314 , -0.058821 ,\n",
              "        0.11235  ,  0.50928  ,  0.14656  , -0.18988  ,  0.24132  ,\n",
              "       -0.038442 ,  0.071418 ,  0.38471  ,  0.10584  , -0.52786  ,\n",
              "       -0.057574 ,  0.13771  , -0.48613  ,  0.62553  , -0.3308   ,\n",
              "       -0.065539 ,  0.1791   ,  0.62746  ,  0.087208 , -0.60422  ,\n",
              "       -0.64595  , -0.2389   , -0.1585   , -0.07948  , -0.037848 ,\n",
              "       -0.205    , -0.44504  , -0.21127  , -0.0026664, -0.0080152,\n",
              "        0.39607  ,  0.069091 , -0.34379  , -0.13992  ,  0.084029 ,\n",
              "       -0.40245  ,  0.094426 ,  0.28908  ,  0.6216   , -0.4132   ,\n",
              "       -0.12153  , -0.40676  , -0.05771  ,  0.17415  ,  0.094069 ,\n",
              "       -0.65955  , -0.34154  , -0.079291 ,  0.16867  ,  0.31665  ,\n",
              "       -0.072868 , -0.44181  , -0.19555  ,  0.16942  , -0.197    ,\n",
              "        0.17484  ,  0.11972  ,  0.012957 , -0.32238  ,  0.33737  ,\n",
              "        0.35553  ,  0.82906  , -0.37521  ,  0.34777  , -0.13105  ,\n",
              "       -0.046688 ,  1.2125   ,  0.025435 , -0.36021  ,  0.65259  ,\n",
              "        0.63729  ,  0.23457  ,  0.19874  ,  0.22589  , -0.016769 ,\n",
              "        0.10671  ,  0.86805  , -0.02853  , -0.011634 , -0.39911  ,\n",
              "        0.12429  , -0.066363 ,  0.0080237,  0.41826  , -0.60603  ,\n",
              "        0.26269  ,  0.035625 , -0.10225  ,  0.44362  , -0.38952  ,\n",
              "       -0.054241 , -0.31542  , -0.076452 , -0.33072  ,  0.42178  ,\n",
              "        0.29242  ,  0.13222  , -0.14896  ,  0.32047  , -0.4735   ,\n",
              "       -0.1093   ,  0.31163  ,  0.49836  , -0.20143  ,  0.36058  ,\n",
              "        0.32242  , -0.11148  ,  0.6416   ,  0.20955  ,  0.035183 ,\n",
              "        0.16684  , -0.41427  , -0.41894  ,  0.18777  ,  0.39424  ,\n",
              "        0.25784  ,  0.18818  ,  0.60567  ,  0.15537  , -0.27121  ,\n",
              "        0.054047 , -0.18342  ,  0.29789  ,  0.35805  , -0.40148  ,\n",
              "       -0.019914 , -0.019742 , -0.56609  , -0.25878  , -0.036075 ,\n",
              "        0.0093725, -0.25284  , -0.061715 , -0.26441  ,  0.47597  ,\n",
              "        0.087956 ,  0.051997 ,  0.21366  , -0.0034455,  0.1739   ,\n",
              "       -0.16853  , -0.22233  , -0.1006   , -0.032696 , -0.008549 ,\n",
              "        0.036532 , -0.19339  , -0.28571  , -0.29294  , -0.53655  ,\n",
              "        0.16387  , -0.36861  , -0.52443  , -0.84287  ,  0.26247  ,\n",
              "        1.8261   ,  0.029467 ,  0.19155  ,  0.28406  , -0.1017   ,\n",
              "       -0.31416  , -0.084328 ,  0.42934  ,  0.32851  ,  0.41274  ,\n",
              "       -0.080323 ,  0.063666 , -0.18441  ,  0.13328  ,  0.46     ,\n",
              "       -0.24984  ,  0.12574  , -0.49056  , -0.072603 ,  0.28191  ,\n",
              "       -0.25738  ,  0.40629  ,  0.38381  , -0.37685  , -0.16371  ,\n",
              "        0.30354  , -0.38234  , -0.61633  , -0.22076  ,  0.38153  ,\n",
              "        0.54091  , -0.32349  , -0.032075 , -0.051326 , -0.12465  ,\n",
              "        0.19237  , -0.077144 ,  0.27005  , -0.20103  , -0.26512  ,\n",
              "        0.35769  , -0.23437  ,  0.054273 ,  0.16901  , -0.15758  ,\n",
              "        0.42714  ,  0.23167  , -0.021318 ,  0.3086   ,  0.44873  ,\n",
              "       -0.12432  , -0.15715  , -0.099448 , -0.24825  ,  1.156    ,\n",
              "       -0.38925  , -0.0063171,  0.48928  ,  0.46089  , -0.17058  ,\n",
              "        0.06118  , -0.54     , -0.054482 ,  0.13329  , -0.47944  ,\n",
              "        0.17119  ,  0.26289  ,  0.14383  , -0.30443  ,  0.27534  ,\n",
              "       -0.14711  , -0.52172  ,  0.32909  , -0.15149  ,  0.1539   ,\n",
              "        0.24171  , -1.6971   ,  0.027579 , -0.0073776,  0.30144  ,\n",
              "        0.011751 ,  0.012419 ,  0.38711  , -0.044167 , -0.62495  ,\n",
              "        0.74536  ,  0.043054 ,  0.62925  , -0.33381  , -0.048651 ,\n",
              "        0.09395  , -0.20336  , -0.055232 ,  0.096572 ,  0.09321  ,\n",
              "       -0.17298  , -0.20794  ,  0.37342  , -0.030166 ,  0.73014  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytj57gjKFx5e",
        "colab_type": "text"
      },
      "source": [
        "Printing words with similar word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-9uyUw0Fl_H",
        "colab_type": "code",
        "outputId": "6c27711f-09ae-418e-8cf9-7ac1f9b1f011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.most_similar('woman'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('girl', 0.7296419112178933), ('man', 0.6998663379619018), ('mother', 0.6899437807604597), ('she', 0.6433226707219909)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul5tomJTF7OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating embedding dictionary\n",
        "embeddings_index = {}\n",
        "\n",
        "for word in model.dictionary:\n",
        "  embedding = model.word_vectors[model.dictionary[word]]\n",
        "  embeddings_index[word] = embedding\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9RDilvsTG8M",
        "colab_type": "code",
        "outputId": "629927c3-62ae-42e4-fce8-db89ea00ecb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embeddings_index[\"the\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCll6PHIKdf",
        "colab_type": "text"
      },
      "source": [
        "**Split Data for training and testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHQMc3hXITWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr,x_test,y_tr,y_test = train_test_split(df['article'],df['summary'],test_size=0.1,random_state=0,shuffle=True) \n",
        "\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(x_tr,y_tr,test_size=0.1,random_state=0,shuffle=True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqdTIfa3IfO-",
        "colab_type": "code",
        "outputId": "cc6a1478-5d13-4375-ed57-c1653246e40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Training data: ', len(x_tr))\n",
        "print('Validation data: ', len(x_val))\n",
        "print('Testing data:', len(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data:  48600\n",
            "Validation data:  5400\n",
            "Testing data: 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRaE1uMG4Ta",
        "colab_type": "text"
      },
      "source": [
        "**Tokenize Data, create vocabulary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6SBJcSeFEbI",
        "colab_type": "text"
      },
      "source": [
        "Article Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMzGnpCWGTqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "before_sample=x_tr[0]\n",
        "# Tokenizer library in keras that maps words to integers, integers to words\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "# padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "after_sample=x_tr[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJwKzOyPXzsu",
        "colab_type": "code",
        "outputId": "ac2fa638-a5a7-4ee5-8b6c-f677c22d53dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "print(\"Aricle Before: \\n\"+str(before_sample[0:250]))\n",
        "print()\n",
        "print(\"Article After: \\n\"+str(after_sample[0:250]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aricle Before: \n",
            "associated press published 14 11 est 25 october 2013 updated 15 36 est 25 october 2013 bishop fargo catholic diocese north dakota exposed potentially hundreds church members fargo grand forks jamestown hepatitis virus late september early october sta\n",
            "\n",
            "Article After: \n",
            "[  975 16914  1822   895     1  2364   815  7506  1941    53   333   435\n",
            "    53   725  1097    53    87   333   751   270 44151    58     7  6515\n",
            "  2086  4555  9328    12  9934   584   267  4429   533    14   190 90116\n",
            "  2139  1452     2  4429   520 21434 21434   451 15124  6378   461   112\n",
            " 12628  6163  8438     8  1504   505  8809   482   693  9934    10  4066\n",
            "   894  1143   817   107  2725   289   885   289  3063  9934  4066   575\n",
            " 25858 12583  8844  3551  1646    21   255   172  1943  3551  1646   707\n",
            " 25858    77  3180  5640    18  2567  1353    54 22048  2417  2579  1391\n",
            "  2952  2789  2557  7592]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_PAIkNFFJcL",
        "colab_type": "text"
      },
      "source": [
        "Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JnZ-NWpIw55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\n",
        "\n",
        "# same for summaries\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ-NgI0FXqOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35pJdzPBJPEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding matrix to be used in model\n",
        "embedding_dim= 300\n",
        "\n",
        "x_embedding_matrix= np.zeros((x_voc_size, embedding_dim))\n",
        "\n",
        "for word, i in x_tokenizer.word_index.items():\n",
        "  if i> x_voc_size:\n",
        "    continue\n",
        "  embedding_vector= embeddings_index.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    x_embedding_matrix[i]= embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7o-zYmt8fgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding matrix for decoder to be used in model\n",
        "y_embedding_matrix= np.zeros((y_voc_size, embedding_dim))\n",
        "\n",
        "for word, i in y_tokenizer.word_index.items():\n",
        "  if i> y_voc_size:\n",
        "    continue\n",
        "  embedding_vector= embeddings_index.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    y_embedding_matrix[i]= embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDWOd3xKKtCH",
        "colab_type": "code",
        "outputId": "78e89a1f-6732-441b-f4a0-66caadb3a153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_embedding_matrix.shape)\n",
        "print(y_embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(202657, 300)\n",
            "(70622, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBuOp5O5Jv9U",
        "colab_type": "text"
      },
      "source": [
        "**Build Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsgqP2ELAW0",
        "colab_type": "code",
        "outputId": "84afd5c5-85b8-4143-d071-5878e72685af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "latent_dim = 300 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,embeddings_initializer= Constant(x_embedding_matrix), trainable=False)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_output1, forward_h, forward_c, backward_h, backward_c = encoder_lstm1(enc_emb)\n",
        "\"\"\"\n",
        "state_h1 = Concatenate()([forward_h, backward_h])\n",
        "state_c1 = Concatenate()([forward_c, backward_c])\n",
        "encoder_states = [state_h1, state_c1]\n",
        "\"\"\"\n",
        "#LSTM 2 \n",
        "# encoder output 1 is fed as input to the next lstm\n",
        "encoder_lstm2 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_output2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_lstm2(encoder_output1)\n",
        "\"\"\"\n",
        "state_h2 = Concatenate()([forward_h2, backward_h2])\n",
        "state_c2 = Concatenate()([forward_c2, backward_c2])\n",
        "encoder_states = [state_h2, state_c2]\n",
        "#encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\"\"\"\n",
        "#LSTM 3 \n",
        "# encoder output 2 fed as input to next lstm \n",
        "encoder_lstm3=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\n",
        "encoder_output3, forward_h3, forward_c3, backward_h3, backward_c3 = encoder_lstm3(encoder_output2)\n",
        "\"\"\"\n",
        "state_h3 = Concatenate()([forward_h3, backward_h3])\n",
        "state_c3 = Concatenate()([forward_c3, backward_c3])\n",
        "encoder_states3 = [state_h3, state_c3]\n",
        "#encoder_output3, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\"\"\"\n",
        "#LSTM 4\n",
        "encoder_lstm4=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\n",
        "encoder_outputs, forward_h4, forward_c4, backward_h4, backward_c4 = encoder_lstm2(encoder_output3)\n",
        "state_h = Concatenate()([forward_h4, backward_h4])\n",
        "state_c = Concatenate()([forward_c4, backward_c4])\n",
        "encoder_states = [state_h, state_c]\n",
        "print(state_h.shape)\n",
        "print(state_c.shape)\n",
        "#encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 600)\n",
            "(None, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do2w6u4s8y3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer=  Embedding(y_voc_size, latent_dim,embeddings_initializer= Constant(y_embedding_matrix), trainable=False)\n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM1\n",
        "# Using encoder_states as decoder's initial state\n",
        "decoder_lstm1 = LSTM(2*latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm1(dec_emb,initial_state=encoder_states) \n",
        "\"\"\"\n",
        "#LSTM2 \n",
        "# Using encoder_states as decoder's initial state\n",
        "decoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_output2,decoder_fwd_state, decoder_back_state = decoder_lstm2(decoder_output1) \n",
        "\n",
        "#LSTM3 \n",
        "# Using encoder_states as decoder's initial state\n",
        "decoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_output3,decoder_fwd_state, decoder_back_state = decoder_lstm3(decoder_output2) \n",
        "\n",
        "#LSTM4\n",
        "# Using encoder_states as decoder's initial state\n",
        "decoder_lstm4 = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm4(decoder_output3) \n",
        "\"\"\"\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBsJUdy1YZDp",
        "colab_type": "code",
        "outputId": "882dc779-e35e-4bd1-8ec6-ae580f36bc03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 2804749563933828371\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 6771025796788876892\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 15457074156647100888\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15701463552\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 4911296353151536754\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1fLcgt9MAxM",
        "colab_type": "code",
        "outputId": "0fe2f365-b431-4dc9-cd36-16706e37e51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# early stopping \n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 300)     60797100    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 100, 600), ( 1442400     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 100, 600), ( 2162400     bidirectional[0][0]              \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 100, 600), ( 2162400     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    21186600    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 600)          0           bidirectional_1[1][1]            \n",
            "                                                                 bidirectional_1[1][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 600)          0           bidirectional_1[1][2]            \n",
            "                                                                 bidirectional_1[1][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 600),  2162400     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 600),  720600      bidirectional_1[1][0]            \n",
            "                                                                 lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1200)   0           lstm_4[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 70622)  84817022    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 175,450,922\n",
            "Trainable params: 93,467,222\n",
            "Non-trainable params: 81,983,700\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuxX57LSMnpF",
        "colab_type": "code",
        "outputId": "653e6ccc-6dc2-46ef-fe52-4eb1a1b43621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=1,batch_size=64, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "760/760 [==============================] - 192s 253ms/step - loss: 6.6296 - val_loss: 6.1707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2zyE5AzM_R7",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation error to check over-fitting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJ9dxGoM7vE",
        "colab_type": "code",
        "outputId": "87b16b00-da87-40e6-c858-2978f73a5df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='val') \n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARTklEQVR4nO3df5Dc9X3f8ecLJBASWBKSQAQ5kdxO+GXHCJ8xjBlKShMDLoUEbDKx60BqM7QexnYnM1bHbUoa/4Hd6SS4HdBgapo/qB0qQpwfNo7xIMgMmM7JUoyMZASyiQ4ic1KBIIIiGL/7x63x6byS9u72brkPz8fMjXb3+9nd9wfNPFm+u3ukqpAkzX1HDXoASVJ/GHRJaoRBl6RGGHRJaoRBl6RGzBvUEy9fvrxWr149qKeXpDlp06ZNe6pqRbdjAwv66tWrGR4eHtTTS9KclOTpQx3zlIskNcKgS1IjDLokNWJg59AlaSpeffVVRkZG2L9//6BHmVELFixg1apVzJ8/v+f7GHRJc8rIyAgnnHACq1evJsmgx5kRVcXevXsZGRlhzZo1Pd/PUy6S5pT9+/ezbNmyZmMOkIRly5ZN+r9CDLqkOaflmP/EVPZo0CWpEQZdkibhhRde4NZbb530/S677DJeeOGFGZjopwy6JE3CoYL+2muvHfZ+X/va11iyZMlMjQX4KRdJmpR169bx1FNPcfbZZzN//nwWLFjA0qVL2b59O0888QRXXnklu3btYv/+/XziE5/g+uuvB37660727dvHpZdeygUXXMDDDz/Mqaeeyle/+lWOO+64ac9m0CXNWb/359/j8Wf/vq+PeebPvYX/fPlZhzx+8803s3XrVrZs2cLGjRt5//vfz9atW1//eOGXvvQlTjzxRF555RXe/e53c9VVV7Fs2bKDHmPHjh18+ctf5otf/CIf/OAHueeee/jwhz887dkNuiRNw7nnnnvQZ8W/8IUvcO+99wKwa9cuduzY8TNBX7NmDWeffTYA73rXu/jhD3/Yl1kMuqQ563CvpGfLokWLXr+8ceNG7r//fh555BEWLlzIRRdd1PWz5Mcee+zrl48++mheeeWVvszim6KSNAknnHACL730UtdjL774IkuXLmXhwoVs376db3/727M6m6/QJWkSli1bxnvf+17e/va3c9xxx3HyySe/fuySSy5h/fr1nHHGGZx22mmcd955szpbqmpWn/AnhoaGyv/BhaTJ2rZtG2ecccagx5gV3faaZFNVDXVb7ykXSWpET0FPsiTJhiTbk2xLcn6XNRcl2ZLke0ke7P+okqTD6fUc+i3AfVV1dZJjgIXjDyZZAtwKXFJVf5vkpD7PKUk6giMGPcli4ELgWoCqOgAcmLDsN4E/qaq/7ax5rr9jSpKOpJdTLmuAUeDOJJuT3JFk0YQ1vwgsTbIxyaYkH+n2QEmuTzKcZHh0dHSao0uSxusl6POAc4Dbqmot8DKwrsuadwHvB94H/Kckvzjxgarq9qoaqqqhFStWTG9ySdJBegn6CDBSVY92rm9gLPAT13yjql6uqj3AQ8A7+zemJM1Nxx9//Kw91xGDXlW7gV1JTuvcdDHw+IRlXwUuSDIvyULgPcC2vk4qSTqsXj/lciNwV+cTLjuB65LcAFBV66tqW5L7gO8CPwbuqKqtMzKxJA3QunXreOtb38rHP/5xAG666SbmzZvHAw88wPPPP8+rr77KZz/7Wa644opZn81vikqaUw769uTX18Hux/r7BCvfAZfefMjDmzdv5pOf/CQPPjj2dZszzzyTb3zjGyxevJi3vOUt7Nmzh/POO48dO3aQhOOPP559+/ZNaZTJflPU3+UiSZOwdu1annvuOZ599llGR0dZunQpK1eu5FOf+hQPPfQQRx11FM888ww/+tGPWLly5azOZtAlzV2HeSU9kz7wgQ+wYcMGdu/ezTXXXMNdd93F6OgomzZtYv78+axevbrrr82daQZdkibpmmuu4WMf+xh79uzhwQcf5O677+akk05i/vz5PPDAAzz99NMDmcugS9IknXXWWbz00kuceuqpnHLKKXzoQx/i8ssv5x3veAdDQ0OcfvrpA5nLoEvSFDz22E/fjF2+fDmPPPJI13VTfUN0Kvz1uZLUCIMuSY0w6JLmnEF9f2Y2TWWPBl3SnLJgwQL27t3bdNSrir1797JgwYJJ3c83RSXNKatWrWJkZITWfwX3ggULWLVq1aTuY9AlzSnz589nzZo1gx7jDclTLpLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUiJ6CnmRJkg1JtifZluT8CccvSvJiki2dn9+dmXElSYcyr8d1twD3VdXVSY4BFnZZ89dV9S/7N5okaTKOGPQki4ELgWsBquoAcGBmx5IkTVYvp1zWAKPAnUk2J7kjyaIu685P8jdJvp7krG4PlOT6JMNJhkdHR6cztyRpgl6CPg84B7itqtYCLwPrJqz5DvALVfVO4L8Df9rtgarq9qoaqqqhFStWTGNsSdJEvQR9BBipqkc71zcwFvjXVdXfV9W+zuWvAfOTLO/rpJKkwzpi0KtqN7AryWmdmy4GHh+/JsnKJOlcPrfzuHv7PKsk6TB6/ZTLjcBdnU+47ASuS3IDQFWtB64G/m2S14BXgN+oqpqJgSVJ3WVQ3R0aGqrh4eGBPLckzVVJNlXVULdjflNUkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpET0FPcmSJBuSbE+yLcn5h1j37iSvJbm6v2NKko5kXo/rbgHuq6qrkxwDLJy4IMnRwOeAv+rjfJKkHh3xFXqSxcCFwP8EqKoDVfVCl6U3AvcAz/V1QklST3o55bIGGAXuTLI5yR1JFo1fkORU4NeA2w73QEmuTzKcZHh0dHTKQ0uSflYvQZ8HnAPcVlVrgZeBdRPW/CHw6ar68eEeqKpur6qhqhpasWLFlAaWJHXXyzn0EWCkqh7tXN/AzwZ9CPhKEoDlwGVJXquqP+3bpJKkwzpi0Ktqd5JdSU6rqu8DFwOPT1iz5ieXk/wv4C+MuSTNrl4/5XIjcFfnEy47geuS3ABQVetnajhJUu96CnpVbWHstMp4XUNeVddOcyZJ0hT4TVFJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RG9BT0JEuSbEiyPcm2JOdPOH5Fku8m2ZJkOMkFMzOuJOlQ5vW47hbgvqq6OskxwMIJx78F/FlVVZJfAu4GTu/jnJKkIzhi0JMsBi4ErgWoqgPAgfFrqmrfuKuLgOrfiJKkXvRyymUNMArcmWRzkjuSLJq4KMmvJdkO/CXw290eKMn1nVMyw6Ojo9MaXJJ0sF6CPg84B7itqtYCLwPrJi6qqnur6nTgSuD3uz1QVd1eVUNVNbRixYppjC1JmqiXoI8AI1X1aOf6BsYC31VVPQS8LcnyPswnSerREYNeVbuBXUlO69x0MfD4+DVJ/mmSdC6fAxwL7O3zrJKkw+j1Uy43And1PuGyE7guyQ0AVbUeuAr4SJJXgVeAa6rKN0YlaRZlUN0dGhqq4eHhgTy3JM1VSTZV1VC3Y35TVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRE9BT3JkiQbkmxPsi3J+ROOfyjJd5M8luThJO+cmXElSYcyr8d1twD3VdXVSY4BFk44/gPgn1XV80kuBW4H3tPHOSVJR3DEoCdZDFwIXAtQVQeAA+PXVNXD465+G1jVvxElSb3o5ZTLGmAUuDPJ5iR3JFl0mPX/Bvh6twNJrk8ynGR4dHR0CuNKkg6ll6DPA84BbquqtcDLwLpuC5P8MmNB/3S341V1e1UNVdXQihUrpjiyJKmbXoI+AoxU1aOd6xsYC/xBkvwScAdwRVXt7d+IkqReHDHoVbUb2JXktM5NFwOPj1+T5OeBPwH+dVU90fcpJUlH1OunXG4E7up8wmUncF2SGwCqaj3wu8Ay4NYkAK9V1dAMzCtJOoSegl5VW4CJgV4/7vhHgY/2cS5J0iT5TVFJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJakSqajBPnIwCTw/kyadnObBn0EPMMvfcvjfbfmHu7vkXqmpFtwMDC/pclWT4zfb/S3XP7Xuz7Rfa3LOnXCSpEQZdkhph0Cfv9kEPMADuuX1vtv1Cg3v2HLokNcJX6JLUCIMuSY0w6F0kOTHJN5Ps6Py59BDrfquzZkeS3+py/M+SbJ35iadvOntOsjDJXybZnuR7SW6e3el7l+SSJN9P8mSSdV2OH5vkjzvHH02yetyx/9C5/ftJ3jebc0/HVPec5FeSbEryWOfPfz7bs0/VdP6eO8d/Psm+JL8zWzP3RVX5M+EH+DywrnN5HfC5LmtOBHZ2/lzaubx03PFfB/43sHXQ+5npPQMLgV/urDkG+Gvg0kHvqcv8RwNPAW/rzPk3wJkT1vw7YH3n8m8Af9y5fGZn/bHAms7jHD3oPc3wntcCP9e5/HbgmUHvZ6b3PO74BuD/AL8z6P1M5sdX6N1dAfxR5/IfAVd2WfM+4JtV9f+q6nngm8AlAEmOB/498NlZmLVfprznqvqHqnoAoKoOAN8BVs3CzJN1LvBkVe3szPkVxvY93vh/DhuAi5Okc/tXquofq+oHwJOdx3ujm/Keq2pzVT3buf17wHFJjp2VqadnOn/PJLkS+AFje55TDHp3J1fV33Uu7wZO7rLmVGDXuOsjndsAfh/4b8A/zNiE/TfdPQOQZAlwOfCtmRhymo44//g1VfUa8CKwrMf7vhFNZ8/jXQV8p6r+cYbm7Kcp77nzYuzTwO/Nwpx9N2/QAwxKkvuBlV0OfWb8laqqJD1/tjPJ2cA/qapPTTwvN2gztedxjz8P+DLwharaObUp9UaT5Czgc8CvDnqWWXAT8AdVta/zgn1OedMGvar+xaGOJflRklOq6u+SnAI812XZM8BF466vAjYC5wNDSX7I2D/fk5JsrKqLGLAZ3PNP3A7sqKo/7MO4M+EZ4K3jrq/q3NZtzUjnX1CLgb093veNaDp7Jskq4F7gI1X11MyP2xfT2fN7gKuTfB5YAvw4yf6q+h8zP3YfDPok/hvxB/ivHPwG4ee7rDmRsfNsSzs/PwBOnLBmNXPnTdFp7Zmx9wvuAY4a9F4Os8d5jL2Ru4afvll21oQ1H+fgN8vu7lw+i4PfFN3J3HhTdDp7XtJZ/+uD3sds7XnCmpuYY2+KDnyAN+IPY+cPvwXsAO4fF60h4I5x636bsTfHngSu6/I4cynoU94zY6+ACtgGbOn8fHTQezrEPi8DnmDsUxCf6dz2X4B/1bm8gLFPNzwJ/F/gbePu+5nO/b7PG/BTPP3eM/AfgZfH/Z1uAU4a9H5m+u953GPMuaD71X9JaoSfcpGkRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRvx/0SBlVCQ3wbQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H6r6c2I14JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "#model = load_model('/content/drive/My Drive/my_model3.h5',custom_objects={'AttentionLayer': AttentionLayer})\n",
        "model.save('/content/drive/My Drive/baseline_attn.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#path = '/content/drive/My Drive/my_model4.h5'\n",
        "#model.save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2yH4JhmGV8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUz8-xOVGWQg",
        "colab_type": "code",
        "outputId": "5b280789-0ba0-42f2-e0e2-7f20ca438eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(reverse_source_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmV89Pg_wzis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "#2 ideas : threshold value if less, remove and if end token found, remove and store in another list and then merge at the end\n",
        "\n",
        "def beam_search(encoder_model,decoder_model, src_input, k, sequence_max_len):\n",
        "\n",
        "    e_out, e_h, e_c = encoder_model.predict(src_input)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    start = True\n",
        "    \n",
        "    #print(k_beam)\n",
        "    # l : point on target sentence to predict\n",
        "    all_k_beams = [[[],1]]\n",
        "    load_hidden={}\n",
        "    end_sentence = []\n",
        "    for l in range(sequence_max_len):\n",
        "\n",
        "        if(start==True):\n",
        "\n",
        "          start=False\n",
        "          output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "          possible_k = output_tokens[0, -1, :].argsort()[-k:][::-1]\n",
        "          #print(\"Possible k in start: \"+str((possible_k)))\n",
        "          dummy_list = []\n",
        "          begin=True\n",
        "          for cand in all_k_beams:\n",
        "            \n",
        "            for curr_k in possible_k:\n",
        "              #print(\"Cand: \"+str(cand)+\" curr_k: \"+str(curr_k))\n",
        "              #print(cand[0]+[curr_k])\n",
        "              #print(cand[1]+np.log(output_tokens[0, -1, :][curr_k]))\n",
        "              curr = [cand[0]+[curr_k],cand[1]-np.log(output_tokens[0, -1, :][curr_k])]\n",
        "              \n",
        "              dummy_list.append(curr)\n",
        "              if(begin==True):\n",
        "                #target_seq = np.zeros((1,1))\n",
        "                #target_seq[0, 0] = curr_k\n",
        "                load_hidden[curr_k] = [h,c]\n",
        "            begin=False\n",
        "          all_k_beams = dummy_list[:]\n",
        "          #print(all_k_beams)\n",
        "          prev_target_seq = copy.deepcopy(possible_k)\n",
        "          #print(\"load_hidden: \"+str(load_hidden.keys()))\n",
        "        else:\n",
        "          #print(\"l is: \"+str(l))\n",
        "          #print(\"In else, prev target seq: \"+str(prev_target_seq))\n",
        "          for target_seq1 in prev_target_seq:\n",
        "            #print(\"Prev index: \"+str(target_seq1))\n",
        "            target_seq = np.zeros((1,1))\n",
        "            target_seq[0, 0] = target_seq1\n",
        "\n",
        "            output_tokens, h, c = decoder_model.predict([target_seq] + [e_out,load_hidden[target_seq1][0],load_hidden[target_seq1][1]])\n",
        "\n",
        "            possible_k = output_tokens[0, -1, :].argsort()[-k:][::-1]\n",
        "            #print(\"Possible k not in start: \"+str((possible_k)))\n",
        "\n",
        "            dummy_list = []\n",
        "            begin = True\n",
        "            for cand in all_k_beams:\n",
        "              for curr_k in possible_k:\n",
        "                if(cand[0][-1]==target_seq1 and len(cand[0])==l):\n",
        "                  #print(\"Here I am\")\n",
        "                  #print(\"Looking at cand: \"+str(cand[0]))\n",
        "                  ended=False\n",
        "                  curr = [cand[0]+[curr_k],cand[1]-np.log(output_tokens[0, -1, :][curr_k])]\n",
        "                  if(curr_k in reverse_target_word_index):\n",
        "                    sampled_token = reverse_target_word_index[curr_k]\n",
        "                    if(sampled_token=='end'):\n",
        "                      end_sentence.append(curr)\n",
        "                      ended=True\n",
        "                  if(ended==False):\n",
        "                    dummy_list.append(curr)\n",
        "                if(begin==True):\n",
        "                  #target_seq = np.zeros((1,1))\n",
        "                  #target_seq[0, 0] = curr_k\n",
        "                  load_hidden[curr_k] = [h,c]\n",
        "              begin=False\n",
        "            all_k_beams +=dummy_list\n",
        "            #print(all_k_beams)\n",
        "            prev_target_seq = copy.deepcopy(possible_k)\n",
        "        \n",
        "        # top k\n",
        "    #print(end_sentence)\n",
        "    all_k_beams += end_sentence\n",
        "    all_k_beams.sort(key=lambda r:r[1])\n",
        "    k_beam = all_k_beams[-k:]\n",
        "    #k_beam = k_beam[::-1]\n",
        "    return k_beam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ5EFfq7GWeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inference Phase \n",
        "\n",
        "\"\"\"\n",
        "After training, the model is tested on new source sequences\n",
        "for which the target sequence is not known \n",
        "setting up inference architecture for it \n",
        "\"\"\"\n",
        "\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(2*latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(2*latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim*2))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm1(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\"\"\"\n",
        "decoder_outputs3, state_h2, state_c2 = decoder_lstm2(decoder_outputs2)\n",
        "decoder_outputs4, state_h2, state_c2 = decoder_lstm3(decoder_outputs3)\n",
        "decoder_outputs5, state_h2, state_c2 = decoder_lstm4(decoder_outputs4)\n",
        "\"\"\"\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs] + [state_h2, state_c2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x9fXLd1jJSpm",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq, search_strat):\n",
        "    # Encode the input as state vectors.\n",
        "\n",
        "    if(search_strat ==\"Beam\"):\n",
        "      decoded_sentence = beam_search(encoder_model,decoder_model, input_seq, 3, 50)\n",
        "    else:\n",
        "      e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "      # Generate empty target sequence of length 1.\n",
        "      target_seq = np.zeros((1,1))\n",
        "\n",
        "      # Chose the 'start' word as the first word of the target sequence\n",
        "      target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "      stop_condition = False\n",
        "      decoded_sentence = ''\n",
        "      \n",
        "      while not stop_condition:\n",
        "          output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "          # Sample a token\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "          if sampled_token_index in reverse_target_word_index:\n",
        "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "          else:\n",
        "            sampled_token=\"UNK\"\n",
        "            \n",
        "          if(sampled_token!='end'):\n",
        "              decoded_sentence += ' '+sampled_token\n",
        "\n",
        "          # Exit condition: either hit max length or find stop word.\n",
        "          if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "              stop_condition = True\n",
        "\n",
        "          # Update the target sequence (of length 1).\n",
        "          target_seq = np.zeros((1,1))\n",
        "          target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "          # Update internal states\n",
        "          e_h, e_c = h, c\n",
        "    \n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k00oOQOQGqSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCyB3qx5b22r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentence(model_summary):\n",
        "  all_Sentence = []\n",
        "  for int_sent in model_summary:\n",
        "    sent = int_sent[0]\n",
        "    decoded_sentence= ''\n",
        "    for sampled_token_index in sent:\n",
        "      if sampled_token_index in reverse_target_word_index:\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "      else:\n",
        "        sampled_token=\"UNK\"\n",
        "            \n",
        "      if(sampled_token!='end'):\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else:\n",
        "        print(\"broken\")\n",
        "        break\n",
        "    #print(str(decoded_sentence)+ \" , \"+str(int_sent[1]))\n",
        "    all_Sentence.append([decoded_sentence,int_sent[1]])\n",
        "  return all_Sentence \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCRO64l4BSNa",
        "colab_type": "code",
        "outputId": "d41b121b-4961-44ac-a1cf-a7d61042c126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "refrence_summary = seq2summary(y_tr[4])\n",
        "search_strat = \"Greedy\" #\"Beam\"\n",
        "model_summary = decode_sequence(x_tr[4].reshape(1,max_len_text),search_strat)\n",
        "\n",
        "print(\"Reference summary: \"+str(refrence_summary))\n",
        "if(search_strat==\"Greedy\"):\n",
        "  print(\"Predicted summary: \"+str(model_summary))\n",
        "else:\n",
        "  all_s=get_sentence(model_summary)\n",
        "  for pred_s in all_s:\n",
        "    print(\"Predicted summary: \"+str(pred_s))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reference summary: to kill himself last week over the tragic embarrassment \n",
            "Predicted summary:  to the world cup cup in the world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r957VgvFMS94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK39b5Ym5Hyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Writing results to file\")\n",
        "fp = open(\"/content/drive/My Drive/Model_summaries.txt\",'w')\n",
        "for i in range(5):\n",
        "  print(seq2summary(y_val[i]))\n",
        "  fp.write(\"Article:\" + seq2text(x_val[i]))\n",
        "  originalSummary = seq2summary(y_val[i])\n",
        "  fp.write(\"\\nOriginal summary:\" + originalSummary)\n",
        "  predictedSummaries_int = decode_sequence(x_val[i].reshape(1,max_len_text))\n",
        "  predictedSummaries=get_sentence(predictedSummaries_int)\n",
        "  for predictedSummary in predictedSummaries:\n",
        "    fp.write(\"\\nPredicted summary:\" + predictedSummary[0])\n",
        "    print(predictedSummary[0])\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(predictedSummary[0], originalSummary) \n",
        "    print(scores[0]['rouge-1']['f'])\n",
        "    print(scores[0]['rouge-l']['f'])\n",
        "    fp.write(\"\\n\")\n",
        "fp.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p4xBdoRLhQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}